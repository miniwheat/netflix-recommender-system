{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5f326db8bed1279d8025ccf538456390",
     "grade": false,
     "grade_id": "cell-3c31370d71a476a6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Grading\n",
    "The final score that you will receive for your programming assignment is generated in relation to the total points set in your programming assignment itemâ€”not the total point value in the nbgrader notebook.<br>\n",
    "When calculating the final score shown to learners, the programming assignment takes the percentage of earned points vs. the total points provided by nbgrader and returns a score matching the equivalent percentage of the point value for the programming assignment. <br>\n",
    "**DO NOT CHANGE VARIABLE OR METHOD SIGNATURES** The autograder will not work properly if your change the variable or method signatures. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2b2ef6efc5deee97a474a1b0d8b07bca",
     "grade": false,
     "grade_id": "cell-fb09c135cd86a7c9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Validate Button\n",
    "Please note that this assignment uses nbgrader to facilitate grading. You will see a **validate button** at the top of your Jupyter notebook. If you hit this button, it will run tests cases for the lab that aren't hidden. It is good to use the validate button before submitting the lab. Do know that the labs in the course contain hidden test cases. The validate button will not let you know whether these test cases pass. After submitting your lab, you can see more information about these hidden test cases in the Grader Output. <br>\n",
    "***Cells with longer execution times will cause the validate button to time out and freeze. Please know that if you run into Validate time-outs, it will not affect the final submission grading.*** <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "32e45eb6bcc8c7d1db2d846fc120d426",
     "grade": false,
     "grade_id": "cell-e212d9fd41f03b18",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Building Recommender Systems for Movie Rating Prediction\n",
    "\n",
    "In this assignment, we will build a recommender systems that predict movie ratings. [MovieLense](https://grouplens.org/datasets/movielens/) has currently 25 million user-movie ratings.  Since the entire data is too big, we use  a 1 million ratings subset [MovieLens 1M](https://www.kaggle.com/odedgolden/movielens-1m-dataset), and we reformatted the data to make it more convenient to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "069f66d81507ea520c1fe5098352b437",
     "grade": false,
     "grade_id": "cell-ea989c7a4eb25b70",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.sparse import coo_matrix, csr_matrix\n",
    "from scipy.spatial.distance import jaccard, cosine \n",
    "from pytest import approx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cdeafa5886528c497f33ffde32d9b7bb",
     "grade": false,
     "grade_id": "cell-476e59a408937946",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "MV_users = pd.read_csv('data/users.csv')\n",
    "MV_movies = pd.read_csv('data/movies.csv')\n",
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a0ddf339d993a9dfb1046fa9c762eb28",
     "grade": false,
     "grade_id": "cell-9dea5c452642998d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "Data = namedtuple('Data', ['users','movies','train','test'])\n",
    "data = Data(MV_users, MV_movies, train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "58249f70f1dc6b13ee151e49b58c073b",
     "grade": false,
     "grade_id": "cell-ee6ea083a19e98e4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Starter codes\n",
    "Now, we will be building a recommender system which has various techniques to predict ratings. \n",
    "The `class RecSys` has baseline prediction methods (such as predicting everything to 3 or to average rating of each user) and other utility functions. `class ContentBased` and `class Collaborative` inherit `class RecSys` and further add methods calculating item-item similarity matrix. You will be completing those functions using what we learned about content-based filtering and collaborative filtering.\n",
    "\n",
    "`RecSys`'s `rating_matrix` method converts the (user id, movie id, rating) triplet from the train data (train data's ratings are known) into a utility matrix for 6040 users and 3883 movies.    \n",
    "Here, we create the utility matrix as a dense matrix (numpy.array) format for convenience. But in a real world data where hundreds of millions of users and items may exist, we won't be able to create the utility matrix in a dense matrix format (For those who are curious why, try measuring the dense matrix self.Mr using .nbytes()). In that case, we may use sparse matrix operations as much as possible and distributed file systems and distributed computing will be needed. Fortunately, our data is small enough to fit in a laptop/pc memory. Also, we will use numpy and scipy.sparse, which allow significantly faster calculations than calculating on pandas.DataFrame object.    \n",
    "In the `rating_matrix` method, pay attention to the index mapping as user IDs and movie IDs are not the same as array index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b203240e52b0e6e18286e3797922e639",
     "grade": false,
     "grade_id": "cell-f9c7ee3867550bb6",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class RecSys():\n",
    "    def __init__(self,data):\n",
    "        self.data=data\n",
    "        self.allusers = list(self.data.users['uID'])\n",
    "        self.allmovies = list(self.data.movies['mID'])\n",
    "        self.genres = list(self.data.movies.columns.drop(['mID', 'title', 'year']))\n",
    "        self.mid2idx = dict(zip(self.data.movies.mID,list(range(len(self.data.movies)))))\n",
    "        self.uid2idx = dict(zip(self.data.users.uID,list(range(len(self.data.users)))))\n",
    "        self.Mr=self.rating_matrix()\n",
    "        self.Mm=None \n",
    "        self.sim=np.zeros((len(self.allmovies),len(self.allmovies)))\n",
    "        \n",
    "    def rating_matrix(self):\n",
    "        \"\"\"\n",
    "        Convert the rating matrix to numpy array of shape (#allusers,#allmovies)\n",
    "        \"\"\"\n",
    "        ind_movie = [self.mid2idx[x] for x in self.data.train.mID] \n",
    "        ind_user = [self.uid2idx[x] for x in self.data.train.uID]\n",
    "        rating_train = list(self.data.train.rating)\n",
    "        \n",
    "        return np.array(coo_matrix((rating_train, (ind_user, ind_movie)), shape=(len(self.allusers), len(self.allmovies))).toarray())\n",
    "\n",
    "\n",
    "    def predict_everything_to_3(self):\n",
    "        \"\"\"\n",
    "        Predict everything to 3 for the test data\n",
    "        \"\"\"\n",
    "        # Generate an array with 3s against all entries in test dataset\n",
    "        # your code here\n",
    "        #np.array([3] * len(self.data.test))\n",
    "        #np.ones(shape=(len(self.data.test,))) * 3\n",
    "        return np.ones_like(self.data.test.rating) * 3\n",
    "        \n",
    "        \n",
    "    def predict_to_user_average(self):\n",
    "        \"\"\"\n",
    "        Predict to average rating for the user.\n",
    "        Returns numpy array of shape (#users,)\n",
    "        \"\"\"\n",
    "        # Generate an array as follows:\n",
    "        # 1. Calculate all avg user rating as sum of ratings of user across all movies/number of movies whose rating > 0\n",
    "        # 2. Return the average rating of users in test data\n",
    "        # your code here\n",
    "        mean_ratings = dict()\n",
    "        test_IDs = self.data.test.uID.unique()\n",
    "        for id in test_IDs:\n",
    "            id_idx = self.uid2idx[id]\n",
    "            ratings = self.Mr[id_idx]\n",
    "            mean_ratings[id] = ratings.sum() / np.count_nonzero(ratings)\n",
    "        yp = []\n",
    "        for i in range(len(self.data.test)):\n",
    "            yp.append(mean_ratings[self.data.test.uID[i]])\n",
    "        yp = np.array(yp)\n",
    "        return yp\n",
    "    \n",
    "    def predict_from_sim(self,uid,mid):\n",
    "        \"\"\"\n",
    "        Predict a user rating on a movie given userID and movieID\n",
    "        \"\"\"\n",
    "        # Predict user rating as follows:\n",
    "        # 1. Get entry of user id in rating matrix\n",
    "        # 2. Get entry of movie id in sim matrix\n",
    "        # 3. Employ 1 and 2 to predict user rating of the movie\n",
    "        # your code here\n",
    "        index_userID = self.uid2idx[uid]\n",
    "        ratings_index_userID = self.Mr[index_userID]\n",
    "        index_movieID = self.mid2idx[mid]\n",
    "        movie_sims = self.sim[index_movieID]\n",
    "        sum_of_sims = np.dot(movie_sims, ratings_index_userID !=0)  # sum of sims where rating != 0\n",
    "        rating = np.dot(ratings_index_userID, movie_sims) / sum_of_sims\n",
    "        \n",
    "        # if there are no similar movies, ie all sims=0 then the rating will be 0\n",
    "        # if rating=0 then predict to user average\n",
    "        if rating == 0:\n",
    "            return self.Mr[index_userID].sum() / np.count_nonzero(self.Mr[index_userID])\n",
    "        else:\n",
    "            return rating\n",
    "        # return rating\n",
    "    \n",
    "    def predict(self):\n",
    "        \"\"\"\n",
    "        Predict ratings in the test data. Returns predicted rating in a numpy array of size (# of rows in testdata,)\n",
    "        \"\"\"\n",
    "        # your code here\n",
    "        yp = np.array([])\n",
    "        for i in range(len(self.data.test)):\n",
    "            uID = self.data.test.iloc[i]['uID']\n",
    "            mID = self.data.test.iloc[i]['mID']\n",
    "            rating = self.predict_from_sim(uID, mID)\n",
    "            yp = np.append(yp, rating)\n",
    "        return yp\n",
    "    \n",
    "    def rmse(self,yp):\n",
    "        yp[np.isnan(yp)]=3 #In case there is nan values in prediction, it will impute to 3.\n",
    "        yt=np.array(self.data.test.rating)\n",
    "        return np.sqrt(((yt-yp)**2).mean())\n",
    "\n",
    "    \n",
    "class ContentBased(RecSys):\n",
    "    def __init__(self,data):\n",
    "        super().__init__(data)\n",
    "        self.data=data\n",
    "        self.Mm = self.calc_movie_feature_matrix()  \n",
    "        \n",
    "    def calc_movie_feature_matrix(self):\n",
    "        \"\"\"\n",
    "        Create movie feature matrix in a numpy array of shape (#allmovies, #genres) \n",
    "        \"\"\"\n",
    "        # your code here\n",
    "        m = self.data.movies.drop(['mID', 'title', 'year'], axis=1)\n",
    "        return np.asmatrix(m)\n",
    "    \n",
    "    def calc_item_item_similarity(self):\n",
    "        \"\"\"\n",
    "        Create item-item similarity using Jaccard similarity\n",
    "        \"\"\"\n",
    "        # Update the sim matrix by calculating item-item similarity using Jaccard similarity\n",
    "        # Jaccard Similarity: J(A, B) = |Aâˆ©B| / |AâˆªB| \n",
    "        # your code here\n",
    "        from sklearn.metrics import pairwise_distances\n",
    "        self.sim = (1 - pairwise_distances(self.Mm, metric='jaccard'))\n",
    "        return\n",
    "        \n",
    "                \n",
    "class Collaborative(RecSys):    \n",
    "    def __init__(self,data):\n",
    "        super().__init__(data)\n",
    "        \n",
    "    def calc_item_item_similarity(self, simfunction, *X):     #simfunction:  'cossim', 'jacsim'\n",
    "        \"\"\"\n",
    "        Create item-item similarity using similarity function. \n",
    "        X is an optional transformed matrix of Mr\n",
    "        \"\"\"    \n",
    "        # General function that calculates item-item similarity based on the sim function and data inputed\n",
    "        if len(X)==0:\n",
    "            self.sim = simfunction()            \n",
    "        else:\n",
    "            self.sim = simfunction(X[0]) # *X passes in a tuple format of (X,), to X[0] will be the actual transformed matrix\n",
    "            \n",
    "    def cossim(self):    \n",
    "        \"\"\"\n",
    "        Calculates item-item similarity for all pairs of items using cosine similarity (values from 0 to 1) on utility matrix\n",
    "        Returns a cosine similarity matrix of size (#all movies, #all movies)\n",
    "        \"\"\"\n",
    "        # Return a sim matrix by calculating item-item similarity for all pairs of items using Jaccard similarity\n",
    "        # Cosine Similarity: C(A, B) = (A.B) / (||A||.||B||) \n",
    "        # your code here\n",
    "        \n",
    "        # create X - a transformed/normalized matrix of .Mr (impute user mean rating for 0 and subtract user mean rating from all)\n",
    "        X = self.Mr.copy().astype(float)\n",
    "        for i in range(len(X)):\n",
    "            user_avg = X[i].sum() / np.count_nonzero(X[i])\n",
    "            np.nan_to_num(user_avg, copy=False)\n",
    "            X[i] = np.where(X[i]==0, X[i], X[i] - user_avg)  # ie  where val=0, val stays 0, else where !=0 set val = val - mean\n",
    "\n",
    "        from sklearn.metrics import pairwise_distances\n",
    "        X_sim = (1 - pairwise_distances(X.T, metric='cosine'))\n",
    "        X_sim = 0.5 + (0.5 * X_sim)\n",
    "        return X_sim\n",
    "        # this solution PASSED all cells\n",
    "        \n",
    "#         # Compute **averaged** movie ratings for all users (movie_ratings_allUsers)\n",
    "#         movie_ratings_allUsers = self.Mr.sum(axis=1) / np.count_nonzero(self.Mr, axis=1)\n",
    "#         np.nan_to_num(movie_ratings_allUsers, copy=False)  # default copy=True\n",
    "\n",
    "#         # Create a sparse matrix for operating cosine on its values\n",
    "#         movie_ratings_array = np.repeat(np.expand_dims(movie_ratings_allUsers, axis=1), self.Mr.shape[1], axis=1)\n",
    "\n",
    "#         # Take care of all the zero ratings (missing value/itentionally we don't know)\n",
    "#         movie_ratings_array_adjusted = self.Mr + (self.Mr==0)*movie_ratings_array - movie_ratings_array\n",
    "\n",
    "#         # Average all the ratings: divide by its magnitude!\n",
    "#         MR_avg = movie_ratings_array_adjusted / (np.sqrt((movie_ratings_array_adjusted**2).sum(axis=0)))\n",
    "\n",
    "#         # Put a Boundary check # 1: since dividing by magnitude may produce inf, zeros, etc. Set nans to 0.\n",
    "#         MR_avg = np.nan_to_num(MR_avg)  # or np.nan_to_num(MR_avg, copy=False)\n",
    "\n",
    "#         # Perform an item-item cosine similarity using: np.dot(matrix.T, matrix)\n",
    "#         sim_mat = np.dot(MR_avg.T, MR_avg)\n",
    "\n",
    "#         # Note that the 289 movies with all zero rating will have cosine sim = 0  -  all same-same movie ratings along diagonal should be 1\n",
    "#         #a = np.argwhere(np.diag(sim_mat) == 0)\n",
    "#         #sim_mat[a, a] = 1  \n",
    "#         # still 42 (other vals along diagonal slightly > 1) - use alt method\n",
    "#         idx = range(sim_mat.shape[0])\n",
    "#         sim_mat[idx, idx] = 1\n",
    "\n",
    "#         # Normalized Cosine Formula:\n",
    "#         sim_mat = 0.5 + (0.5 * sim_mat)\n",
    "\n",
    "#         return sim_mat\n",
    "\n",
    "    \n",
    "    def jacsim(self,Xr):\n",
    "        \"\"\"\n",
    "        Calculates item-item similarity for all pairs of items using jaccard similarity (values from 0 to 1)\n",
    "        Xr is the transformed rating matrix.\n",
    "        \"\"\"    \n",
    "        # Return a sim matrix by calculating item-item similarity for all pairs of items using Jaccard similarity\n",
    "        # Jaccard Similarity: J(A, B) = |Aâˆ©B| / |AâˆªB| \n",
    "        # your code here\n",
    "        \n",
    "#         # Convert Xr into a CSR format\n",
    "#         # csr0 = csr_matrix((Xr>0).astype(int))\n",
    "#         X = csr_matrix(Xr)\n",
    "\n",
    "#         # get the intersection\n",
    "#         # produces a n x n matrix of the intersection values, ie [0,1] is the intersection between col 0 and col 1 which is value 3\n",
    "#         a = (X > 0).astype(int)\n",
    "#         nz_intersect = np.dot(a.T, a)\n",
    "        \n",
    "        \n",
    "        n = Xr.shape[1]\n",
    "        max_val = int(Xr.max())\n",
    "        nz_intersect = np.zeros((n,n)).astype(int)\n",
    "        for i in range(1, max_val + 1):\n",
    "                csrm = csr_matrix((Xr == i)).astype(int)\n",
    "                nz_intersect = nz_intersect + np.array(np.dot(csrm.T, csrm).toarray()).astype(int)\n",
    "\n",
    "        # get the union\n",
    "\n",
    "        # get the nonzero counts of each column\n",
    "        #colsums = A.sum(axis=0)  # alternatively\n",
    "        colsums = np.count_nonzero(Xr, axis=0)  # alternatively\n",
    "\n",
    "        # get matrix of sum of colsums between columns\n",
    "        # start with matrix of n x n where row vals = sum for corresponding column eg col 1 = 4, all row[0] vals = 4\n",
    "        n = Xr.shape[1] # how many movies / columns\n",
    "        colsums_mat = np.repeat(colsums.reshape(n,1), n, axis=1)\n",
    "        # add the colsum matrix to its transpose to get the pairs\n",
    "        colsums_pairs = colsums_mat + colsums_mat.T\n",
    "\n",
    "        # to get the union:  subtract the intersection of a pair from the column sums of the two colums  eg col 1 = 4, col 2 = 3; total = 7, int = 3 ---> untion = 4\n",
    "        union = colsums_pairs - nz_intersect\n",
    "\n",
    "        # calculate jaccard similarity\n",
    "        sim = nz_intersect / union\n",
    "        np.nan_to_num(sim, copy=False)  # NaNs potentially generated when union is zero\n",
    "\n",
    "        d = np.argwhere(np.diag(sim) != 1)\n",
    "        sim[d, d] = 1\n",
    "        \n",
    "        return np.array(sim)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7da30c84f0fadd1ae2193af99888f526",
     "grade": false,
     "grade_id": "cell-5efe89bc06f7e6c5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Q1. Baseline models [15 pts]\n",
    "\n",
    "### 1a. Complete the function `predict_everything_to_3` in the class `RecSys`  [5 pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bdd5d6c687c352a1ea45cfed3c7380eb",
     "grade": false,
     "grade_id": "cell-749c77774f53cfe1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Creating Sample test data\n",
    "np.random.seed(42)\n",
    "sample_train = train[:30000]\n",
    "sample_test = test[:30000]\n",
    "\n",
    "\n",
    "sample_MV_users = MV_users[(MV_users.uID.isin(sample_train.uID)) | (MV_users.uID.isin(sample_test.uID))]\n",
    "sample_MV_movies = MV_movies[(MV_movies.mID.isin(sample_train.mID)) | (MV_movies.mID.isin(sample_test.mID))]\n",
    "\n",
    "\n",
    "sample_data = Data(sample_MV_users, sample_MV_movies, sample_train, sample_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6a92dff8931c33032133faadb8a1b370",
     "grade": true,
     "grade_id": "cell-75645797e3541a77",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2642784503423288\n"
     ]
    }
   ],
   "source": [
    "# Sample tests predict_everything_to_3 in class RecSys\n",
    "\n",
    "sample_rs = RecSys(sample_data)\n",
    "sample_yp = sample_rs.predict_everything_to_3()\n",
    "print(sample_rs.rmse(sample_yp))\n",
    "assert sample_rs.rmse(sample_yp)==approx(1.2642784503423288, abs=1e-3), \"Did you predict everything to 3 for the test data?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# passed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "15f5468947b1c6e116c2fa0fd70f70c8",
     "grade": true,
     "grade_id": "cell-52f19a05e8a8b1a3",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2585510334053043\n"
     ]
    }
   ],
   "source": [
    "# Hidden tests predict_everything_to_3 in class RecSys\n",
    "rs = RecSys(data)\n",
    "yp = rs.predict_everything_to_3()\n",
    "print(rs.rmse(yp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2585510334053043\n"
     ]
    }
   ],
   "source": [
    "method_yp3 = rs.rmse(yp)\n",
    "print(method_yp3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# passed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "38a23786301e38ef9c85f0c3620a0a9b",
     "grade": false,
     "grade_id": "cell-e32e46bf9f33dbb3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1b. Complete the function predict_to_user_average in the class RecSys [10 pts]\n",
    "Hint: Include rated items only when averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     def predict_to_user_average(self):\n",
    "#         all_ratings = pd.concat((self.data.train, self.data.test))\n",
    "#         uIDs = all_ratings.uID.unique()\n",
    "#         avg_user_ratings = dict()\n",
    "#         for uID in uIDs:\n",
    "#             avg_rating = self.data.train[(self.data.train.uID == uID) & (self.data.train.rating > 0)].rating.mean()\n",
    "#             avg_user_ratings[uID] = avg_rating\n",
    "#         yp = np.array([])\n",
    "#         for index, row in self.data.test.iterrows():\n",
    "#             yp = np.append(yp, avg_user_ratings[row['uID']])\n",
    "#         return yp\n",
    "\n",
    "# passes both tests below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_ratings = dict()\n",
    "# test_IDs = sample_rs.data.test.uID.unique()\n",
    "# for id in test_IDs:\n",
    "#     id_idx = sample_rs.uid2idx[id]\n",
    "#     ratings = sample_rs.Mr[id_idx]\n",
    "#     mean_ratings[id] = ratings.sum() / np.count_nonzero(ratings)\n",
    "    \n",
    "# yp = np.array([])\n",
    "# for index, row in sample_rs.data.test.iterrows():\n",
    "#     yp = np.append(yp, mean_ratings[row['uID']])\n",
    "\n",
    "# yp = []\n",
    "# for i in range(len(sample_rs.data.test)):\n",
    "#     yp.append(mean_ratings[sample_rs.data.test.uID[i]])\n",
    "# yp = np.array(yp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7939100c207d632a6588064be95e86d1",
     "grade": true,
     "grade_id": "cell-5f918ef5c3068eb7",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1429596846619763\n"
     ]
    }
   ],
   "source": [
    "# Sample tests predict_to_user_average in the class RecSys\n",
    "sample_yp = sample_rs.predict_to_user_average()\n",
    "print(sample_rs.rmse(sample_yp))\n",
    "assert sample_rs.rmse(sample_yp)==approx(1.1429596846619763, abs=1e-3), \"Check predict_to_user_average in the RecSys class. Did you predict to average rating for the user?\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# passed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "870acf1d0ebd4b98fe4d170503948eb7",
     "grade": true,
     "grade_id": "cell-dbe3ae17d138f001",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0352910334228647\n"
     ]
    }
   ],
   "source": [
    "# Hidden tests predict_to_user_average in the class RecSys\n",
    "yp = rs.predict_to_user_average()\n",
    "print(rs.rmse(yp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0352910334228647\n"
     ]
    }
   ],
   "source": [
    "method2_ypavg = rs.rmse(yp)\n",
    "print(method2_ypavg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# passed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "531bc11d4bb9ad16238bb3c6436cf1de",
     "grade": false,
     "grade_id": "cell-2e517f5f3bb7bc8e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Q2. Content-Based model [25 pts]\n",
    "\n",
    "### 2a. Complete the function calc_movie_feature_matrix in the class ContentBased [5 pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9f4e132a376edada87d141fbcbabcdf9",
     "grade": false,
     "grade_id": "cell-0fd9bcbcf2e542fd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "cb = ContentBased(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "16dc8acd6f1516386ebd64246d791bcc",
     "grade": true,
     "grade_id": "cell-232d6022e1da2f62",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# tests calc_movie_feature_matrix in the class ContentBased \n",
    "assert(cb.Mm.shape==(3883, 18))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# passed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e149458337a6465af9cdafbef0cb872d",
     "grade": false,
     "grade_id": "cell-a959245b68dc1033",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 2b. Complete the function calc_item_item_similarity in the class ContentBased [10 pts]\n",
    "This function updates `self.sim` and does not return a value.    \n",
    "Some factors to think about:     \n",
    "1. The movie feature matrix has binary elements. Which similarity metric should be used?\n",
    "2. What is the computation complexity (time complexity) on similarity calcuation?      \n",
    "Hint: You may use functions in the `scipy.spatial.distance` module on the dense matrix, but it is quite slow (think about the time complexity). If you want to speed up, you may try using functions in the `scipy.sparse` module. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3152.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import pairwise_distances\n",
    "my_cb = ContentBased(sample_data)\n",
    "sim_mat = (1 - pairwise_distances(my_cb.Mm, metric='jaccard'))\n",
    "np.trace(sim_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3152.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.spatial.distance import pdist, squareform\n",
    "sim_mat = (1 - squareform(pdist(my_cb.Mm, metric='jaccard')))\n",
    "np.trace(sim_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb.calc_item_item_similarity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7bfb32e08a1d2ecab886c4926f35af4b",
     "grade": true,
     "grade_id": "cell-b88ed74a662c75ac",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Sample tests calc_item_item_similarity in ContentBased class \n",
    "\n",
    "sample_cb = ContentBased(sample_data)\n",
    "sample_cb.calc_item_item_similarity() \n",
    "\n",
    "# print(np.trace(sample_cb.sim))\n",
    "# print(sample_cb.sim[10:13,10:13])\n",
    "assert(sample_cb.sim.sum() > 0), \"Check calc_item_item_similarity.\"\n",
    "assert(np.trace(sample_cb.sim) == 3152), \"Check calc_item_item_similarity. What do you think np.trace(cb.sim) should be?\"\n",
    "\n",
    "\n",
    "ans = np.array([[1, 0.25, 0.],[0.25, 1, 0.],[0., 0., 1]])\n",
    "for pred, true in zip(sample_cb.sim[10:13, 10:13], ans):\n",
    "    assert approx(pred, 0.01) == true, \"Check calc_item_item_similarity. Look at cb.sim\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "86d346bdb7d00d615f915bc87c7c0e8b",
     "grade": true,
     "grade_id": "cell-b1260c5ba472d43b",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# tests calc_item_item_similarity in ContentBased class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7b236c6f66a5cd271b27120fadb39cfa",
     "grade": true,
     "grade_id": "cell-4a8dc462fa8d33f0",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# additional tests for calc_item_item_similarity in ContentBased class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cffd601726e01f148136dccbd545d8fc",
     "grade": true,
     "grade_id": "cell-3b1eb8e79527f012",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# additional tests for calc_item_item_similarity in ContentBased class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "475617bb2e9c2f8ef44e29fd789e3bed",
     "grade": true,
     "grade_id": "cell-64689afe942eba5a",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# additional tests for calc_item_item_similarity in ContentBased class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d36bff79d05688a58351743d920c579e",
     "grade": true,
     "grade_id": "cell-a7be29cab0d2e38a",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# additional tests for calc_item_item_similarity in ContentBased class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# passed all above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6e97e513ad0659d93e513354f7d6a1bd",
     "grade": false,
     "grade_id": "cell-eec0c5d6e29e72f5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 2c. Complete the function predict_from_sim in the class RecSys [5 pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2c791b828031bb24a9c0df5af8102a25",
     "grade": true,
     "grade_id": "cell-2d79f53ecabb1abf",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# for a, b in zip(sample_MV_users.uID, sample_MV_movies.mID):\n",
    "#     print(a, b, sample_cb.predict_from_sim(a,b))\n",
    "\n",
    "# Sample tests for predict_from_sim in RecSys class \n",
    "assert(sample_cb.predict_from_sim(245,276)==approx(2.5128205128205128,abs=1e-2)), \"Check predict_from_sim. Look at how you predicted a user rating on a movie given UserID and movieID.\"\n",
    "assert(sample_cb.predict_from_sim(2026,2436)==approx(2.785714285714286,abs=1e-2)), \"Check predict_from_sim. Look at how you predicted a user rating on a movie given UserID and movieID.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# passed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index_userID = sample_cb.uid2idx[245]\n",
    "# ratings_index_userID = sample_cb.Mr[index_userID]\n",
    "# index_movieID = sample_cb.mid2idx[276]\n",
    "# movie_sims = sample_cb.sim[index_movieID]\n",
    "\n",
    "# sum_of_sims = np.dot(movie_sims, ratings_index_userID !=0)\n",
    "# np.dot(ratings_index_userID, movie_sims) / sum_of_sims\n",
    "\n",
    "# # idx = np.nonzero(np.array(ratings_index_userID))\n",
    "# # x = np.array(movie_sims)[idx].sum()\n",
    "# # np.dot(ratings_index_userID, movie_sims) / x\n",
    "\n",
    "# # if the rating is zero, ie all similarity scores ar zero, then compute user average\n",
    "# sample_cb.Mr[index_userID].sum() / np.count_nonzero(sample_cb.Mr[index_userID])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "55a16fffbf7cbf657fc0133973bddc59",
     "grade": true,
     "grade_id": "cell-a83193bd93c45044",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# tests for predict_from_sim in RecSys class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# passed - only after multiple attempts and finally kernel restart!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1dfb42c210f38f2b616193822663af52",
     "grade": false,
     "grade_id": "cell-4dbdef2549c27d3b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 2d. Complete the function predict in the class RecSys [5 pts]\n",
    "After completing the predict method in the RecSys class, run the cell below to calculate rating prediction and RMSE. How much does the performance increase compared to the baseline results from above? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e8c34be7bd867ea3521024fb6ab4a03c",
     "grade": true,
     "grade_id": "cell-7d6e299ec837ac9e",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1962537249116723\n"
     ]
    }
   ],
   "source": [
    "# Sample tests method predict in the RecSys class \n",
    "\n",
    "sample_yp = sample_cb.predict()\n",
    "sample_rmse = sample_cb.rmse(sample_yp)\n",
    "print(sample_rmse)\n",
    "\n",
    "assert(sample_rmse==approx(1.1962537249116723, abs=1e-2)), \"Check method predict in the RecSys class.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# passed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yp = np.array([])\n",
    "# for i in range(len(sample_cb.data.test)):\n",
    "#     uID = sample_cb.data.test.iloc[i]['uID']\n",
    "#     mID = sample_cb.data.test.iloc[i]['mID']\n",
    "#     rating = sample_cb.predict_from_sim(uID, mID)\n",
    "#     yp = np.append(yp, rating)\n",
    "\n",
    "# sample_cb.rmse(yp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "00c2f93e788dd22360e67f5ef88521a7",
     "grade": false,
     "grade_id": "cell-3232e0e311e56e19",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0128116783754684\n"
     ]
    }
   ],
   "source": [
    "# Hidden tests method predict in the RecSys class \n",
    "\n",
    "yp = cb.predict()\n",
    "rmse = cb.rmse(yp)\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fec9587776c5364a637967f5ec7067cf",
     "grade": true,
     "grade_id": "cell-a8a3fa60da47abcf",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# tests method predict in the RecSys class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0128116783754684\n"
     ]
    }
   ],
   "source": [
    "method3_cb_ii = rmse\n",
    "print(method3_cb_ii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# passed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "44f2a6ef3ef78c7ffa924dd74e309beb",
     "grade": false,
     "grade_id": "cell-563e07a0cadec0db",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Q3. Collaborative Filtering\n",
    "\n",
    "### 3a. Complete the function cossim in the class Collaborative [10 pts]\n",
    "**To Do:**    \n",
    "1.Impute the unrated entries in self.Mr to the user's average rating then subtract by the user mean, call this matrix X.   \n",
    "2.Calculate cosine similarity for all item-item pairs. Don't forget to rescale the cosine similarity to be 0~1.    \n",
    "You might encounter divide by zero warning (numpy will fill nan value for that entry). In that case, you can fill those with appropriate values.    \n",
    "\n",
    "Hint: Let's say a movie item has not been rated by anyone. When you calculate similarity of this vector to anoter, you will get $\\vec{0}$=[0,0,0,....,0]. When you normalize this vector, you'll get divide by zero warning and it will make nan value in self.sim matrix. Theoretically what should the similarity value for $\\vec{x}_i \\cdot \\vec{x}_i$ when $\\vec{x}_i = \\vec{0}$? What about $\\vec{x}_i \\cdot \\vec{x}_j$ when $\\vec{x}_i = \\vec{0}$ and $\\vec{x}_j$ is an any vector?     \n",
    "\n",
    "Hint: You may use `scipy.spatial.distance.cosine`, but it will be slow because its cosine function does vector-vector operation whereas you can implement matrix-matrix operation using numpy to calculate all cosines all at once (it can be 100 times faster than vector-vector operation in our data). Also pay attention to the definition. The scipy.spatial.distance provides distance, not similarity. \n",
    "\n",
    "3. Run the below cell that calculate yp and RMSE. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4b6366ed3397587780416b7fa65f1456",
     "grade": true,
     "grade_id": "cell-054a0416525e124f",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Sample tests cossim method in the Collaborative class\n",
    "\n",
    "sample_cf = Collaborative(sample_data)\n",
    "sample_cf.calc_item_item_similarity(sample_cf.cossim)\n",
    "sample_yp = sample_cf.predict()\n",
    "sample_rmse = sample_cf.rmse(sample_yp)\n",
    "\n",
    "assert(np.trace(sample_cf.sim)==3152), \"Check cossim method in the Collaborative class. What should np.trace(cf.sim) equal?\"\n",
    "assert(sample_rmse==approx(1.1429596846619763, abs=5e-3)), \"Check cossim method in the Collaborative class. rmse result is not as expected.\"\n",
    "assert(sample_cf.sim[0,:3]==approx([1., 0.5, 0.5],abs=1e-2)), \"Check cossim method in the Collaborative class. cf.sim isn't giving the expected results.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# passed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = sample_cf.Mr.copy()\n",
    "# for i in range(len(X)):\n",
    "#     user_avg = X[i].sum() / np.count_nonzero(X[i])\n",
    "#     X[i] = np.where(X[i]==0, X[i], X[i] - user_avg)  # ie  where val=0, val stays 0, else where !=0 set val = val - mean\n",
    "\n",
    "# from sklearn.metrics import pairwise_distances\n",
    "# X_sim = (1 - pairwise_distances(X.T, metric='cosine'))\n",
    "# X_sim = 0.5 + (0.5 * X_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18153888\n",
      "30000\n",
      "False\n",
      "total rows: 5769\n",
      "rows all zero: 585\n",
      "rows not all zero: 5184\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([   0,    0,    1, ..., 5768, 5768, 5768]),\n",
       " array([ 463,  518,  694, ..., 1121, 1793, 2819]))"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.count_nonzero(sample_cf.Mr==0))  # how many values are zero?\n",
    "print(np.count_nonzero(sample_cf.Mr))     # how many values are non zero?\n",
    "print(np.any(np.isnan(sample_cf.Mr)))     # are any values NaN?\n",
    "print('total rows:', sample_cf.Mr.shape[0])\n",
    "print('rows all zero:', np.all(sample_cf.Mr==0, axis=1).sum())  # how many rows are all zero?\n",
    "print('rows not all zero:', np.any(sample_cf.Mr, axis=1).sum())     # how many rows have at least one rating?\n",
    "\n",
    "np.nonzero(sample_cf.Mr)  # returns tuple of indices of nonzero values (array of dim_1, array of dim_2)\n",
    "np.where(sample_cf.Mr!=0) # equivalent to np.nonzero - returns indices where val!=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.9403746653744962"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cosine calculation examples from lecture\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "a = np.array([5, 0, 1, 4])\n",
    "b = np.array([2, 3, 5, 0])\n",
    "c = np.array([4, 4, 0, 4])\n",
    "(1 - cosine(a, b))  # 0.375\n",
    "\n",
    "# impute Nan/0 to neutral value 3\n",
    "a = np.array([5, 3, 1, 4])\n",
    "b = np.array([2, 3, 5, 3])\n",
    "c = np.array([4, 4, 3, 4])\n",
    "(1 - cosine(a, b))  # 0.74\n",
    "\n",
    "# impute to 3 (and subtract 3)\n",
    "a = np.array([5, 3, 1, 4]) - 3\n",
    "b = np.array([2, 3, 5, 3]) - 3\n",
    "(1 - cosine(a, b))  # -0.89\n",
    "\n",
    "# normalize by user mean:  impute NaN/0 vals to mean (and subtract mean from all)\n",
    "a = np.array([5, 3.25, 1, 4, 3]) - 3.25\n",
    "b = np.array([2, 3, 5, 3.25, 3]) - 3.25\n",
    "(1 - cosine(a, b))  # -0.94"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example of np.expand\n",
    "# np.expand_dims(a, axis)\n",
    "x = np.array([1, 2])\n",
    "x.shape # (2,)\n",
    "y = np.expand_dims(x, axis=0)  # equivalent to x[np.newaxis, :] or x[np.newaxis]\n",
    "y.shape # (1, 2)\n",
    "y = np.expand_dims(x, axis=1)  # equivalent to x[:, np.newaxis]\n",
    "y.shape # (2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 2, 2, 2],\n",
       "       [3, 3, 3, 4, 4, 4]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example of np.repeat\n",
    "# np.repeat(a, repeats, axis=None)   Output array which has the same shape as a, except along the given axis\n",
    "np.repeat(3, 4)\n",
    "x = np.array([[1,2],[3,4]])\n",
    "np.repeat(x, 2)\n",
    "np.repeat(x, 3, axis=1)    #np.repeat(x, 3, axis=0)\n",
    "# np.repeat(x, [1, 2], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = sample_cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute **averaged** movie ratings for all users (movie_ratings_allUsers)\n",
    "movie_ratings_allUsers = test.Mr.sum(axis=1) / np.count_nonzero(test.Mr, axis=1)\n",
    "np.isnan(movie_ratings_allUsers).sum() #585 NaNs\n",
    "\n",
    "# replace the NaNs with 0\n",
    "np.nan_to_num(movie_ratings_allUsers, copy=False)  # default copy=True\n",
    "np.isnan(movie_ratings_allUsers).sum()  # 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5769, 3152)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a sparse matrix for operating cosine on its values\n",
    "movie_ratings_array = np.repeat(np.expand_dims(movie_ratings_allUsers, axis=1), test.Mr.shape[1], axis=1)\n",
    "movie_ratings_array.shape # (5769, 3152)  # no NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5769, 3152)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take care of all the zero ratings (missing value/itentionally we don't know)\n",
    "movie_ratings_array_adjusted = test.Mr + (test.Mr==0)*movie_ratings_array - movie_ratings_array\n",
    "# takes the original Mr, uses a bool matrix (where vals==0) * ratings to impute all zero vals to the mean for user\n",
    "# then subtracts the mean from all values\n",
    "movie_ratings_array_adjusted.shape  # (5769, 3152)  # no NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "289"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# are there columns that are all zero?  that will produce a norm=zero and div/0 --> NaN\n",
    "np.all(movie_ratings_array_adjusted == 0, axis=0).sum() #289"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average all the ratings: divide by its magnitude!\n",
    "MR_avg = movie_ratings_array_adjusted / (np.sqrt((movie_ratings_array_adjusted**2).sum(axis=0)))\n",
    "# note that np.sqrt((movie_ratings_array_adjusted**2).sum(axis=0)) should be equivalent to \n",
    "#    np.linalg.norm(movie_ratings_array_adjusted, ord=2, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "289"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(MR_avg).sum()  # 5769 users x 289 movies with all zero ratings = 1667241\n",
    "np.all(np.isnan(MR_avg), axis=0).sum()  # 289 columns with all NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "289"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Put a Boundary check # 1: since dividing by magnitude may produce inf, zeros, etc. Set nans to 0.\n",
    "\n",
    "# numpy.nan_to_num(x, copy=True, nan=0.0, posinf=None, neginf=None)\n",
    "MR_avg = np.nan_to_num(MR_avg)  # or np.nan_to_num(MR_avg, copy=False)\n",
    "MR_avg.shape  # (5769, 3152)\n",
    "np.isnan(MR_avg).sum() # 0\n",
    "np.count_nonzero(np.all(MR_avg == 0, axis=0))  # 289 columns are all zero (as expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform an item-item cosine similarity using: np.dot(matrix.T, matrix)\n",
    "sim_mat = np.dot(MR_avg.T, MR_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2863.0"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note that the 289 movies with all zero rating will have cosine sim = 0\n",
    "sim_mat.shape     # (3152, 3152)\n",
    "sim_mat.trace()   # trace is 2863 (not 3152)\n",
    "np.count_nonzero(np.diag(sim_mat) == 0)  # 289"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3152.0"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.argwhere(np.diag(sim_mat) == 0)\n",
    "b = np.argwhere(np.all(movie_ratings_array_adjusted == 0, axis=0))\n",
    "np.all(np.equal(a, b))  # True\n",
    "\n",
    "sim_mat[a, b].sum()\n",
    "sim_mat[a, a].sum()  # 0\n",
    "\n",
    "sim_mat[a, a] = 1\n",
    "sim_mat.trace()  # 3152"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# But note!\n",
    "np.count_nonzero(np.diag(sim_mat) > 1) # 42\n",
    "# must be corrected to 1 - autograder checks max == 1\n",
    "sim_mat[range(sim_mat.shape[0]), range(sim_mat.shape[0])] = 1\n",
    "np.count_nonzero(np.diag(sim_mat) > 1)  # 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3152.0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalized Cosine Formula:\n",
    "sim_mat = 0.5 + (0.5 * sim_mat)\n",
    "sim_mat.trace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5eb656568ac143aa7e40c212d53eb020",
     "grade": false,
     "grade_id": "cell-49a2c83fd032cee6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0263081874204125\n"
     ]
    }
   ],
   "source": [
    "# Hidden tests cossim method in the Collaborative class\n",
    "\n",
    "cf = Collaborative(data)\n",
    "cf.calc_item_item_similarity(cf.cossim)\n",
    "yp = cf.predict()\n",
    "rmse = cf.rmse(yp)\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method \"B\" rmse = 1.0263081874204125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0263081874204125\n"
     ]
    }
   ],
   "source": [
    "method4_cb_cosine = rmse\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "31b5a8be7a888dea0fba0148175c7622",
     "grade": true,
     "grade_id": "cell-126fb0d12b2c66e7",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# tests cossim method in the Collaborative class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "800ff371c38a877b0285b0f45cc18f1a",
     "grade": true,
     "grade_id": "cell-9e6bc1c31e566d76",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# additional tests for cossim method in the Collaborative class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d85d53d1945355c60edbd3eb99a2223a",
     "grade": true,
     "grade_id": "cell-7b9c0acd25eaadda",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# additional tests for cossim method in the Collaborative class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a7bd4b4a85ca2d4efa551f602bde298f",
     "grade": true,
     "grade_id": "cell-369189aa9a403a0f",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# additional tests for cossim method in the Collaborative class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b337a1c35dade446f7572c74d2a14fe6",
     "grade": true,
     "grade_id": "cell-bfde47a18fccd03d",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# additional tests for cossim method in the Collaborative class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3ff727b57a52eb37221feb12d09e0f7a",
     "grade": true,
     "grade_id": "cell-cb7766e929ce12ef",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# additional tests for cossim method in the Collaborative class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all cells passed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "15dbe8e3743dd847b4292cc46184e163",
     "grade": false,
     "grade_id": "cell-6dd829484cdb0a9f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 3b. Complete the function jacsim in the class Collaborative [15 pts]\n",
    "**3b [15 pts] = 3b-i) [5 pts]+3b-ii) [5 pts]+ 3b-iii) [5 pts]**\n",
    "\n",
    "Function `jacsim` calculates jaccard similarity between items using collaborative filtering method. When we have a rating matrix `self.Mr`, the entries of Mr matrix are 0 to 5 (0: unrated, 1-5: rating). We are interested to see which threshold method works better when we use jaccard dimilarity in the collaborative filtering.    \n",
    "We may treat any rating 3 or above to be 1 and the negatively rated (below 3) and no-rating as 0. Or, we may treat movies with any ratings to be 1 and ones that has no rating as 0. In this question, we will complete a function jacsim that takes a transformed rating matrix X and calculate and returns a jaccard similarity matrix.     \n",
    "Let's consider these input cases for the utility matrix $M_r$ with ratings 1-5 and 0s for no-rating.    \n",
    "1. $M_r \\geq 3$ \n",
    "2. $M_r \\geq 0$ \n",
    "3. $M_r$, no transform.\n",
    "\n",
    "Things to think about: \n",
    "- The cases 1 and 2 are straightforward to calculate Jaccard, but what does Jaccard mean for multicategory data?\n",
    "- Time complexity: The matrix $M_r$ is much bigger than the item feature matrix $M_m$, therefore it will take very long time if we calculate on dense matrix.     \n",
    "Hint: Use sparse matrix.\n",
    "- Which method will give the best performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4e73ce8798c3e0387a575fb5b47b628c",
     "grade": false,
     "grade_id": "cell-3cc4678686ede231",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 3b-i)  When $M_r\\geq3$ [5 pts]\n",
    "After you've implemented the jacsim function, run the code below. If implemented correctly, you'll have RMSE below 0.99. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d80694c2f4ea5b45f954a89f29d4e9a1",
     "grade": false,
     "grade_id": "cell-e0d9354a7b488cca",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarity calculation time 1.5387999191880226\n",
      "0.9819058692126349\n"
     ]
    }
   ],
   "source": [
    "cf = Collaborative(data)\n",
    "Xr = cf.Mr>=3\n",
    "t0=time.perf_counter()\n",
    "cf.calc_item_item_similarity(cf.jacsim,Xr)\n",
    "t1=time.perf_counter()\n",
    "time_sim = t1-t0\n",
    "print('similarity calculation time',time_sim)\n",
    "yp = cf.predict()\n",
    "rmse = cf.rmse(yp)\n",
    "print(rmse)\n",
    "assert(rmse<0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "71319b1d93a7f9232023bf05ea90202e",
     "grade": true,
     "grade_id": "cell-a80d917298a5c254",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# tests RMSE for jacsim implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4997d897c391218cac8f5c3aaf2bcc07",
     "grade": true,
     "grade_id": "cell-fdebe2b922817f71",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# additional tests for RMSE for jacsim implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3f81809af169f5c527bca4a1738f646f",
     "grade": true,
     "grade_id": "cell-ba2fba2da48d3160",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# additional tests for jacsim implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** did not pass single cell above ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "49c97e825ef7bd0b32ab4ad5bc378458",
     "grade": true,
     "grade_id": "cell-f7e1c6f239e3155f",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# additional tests for jacsim implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# passed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d7d6ac2ac83c2e4a79834f05debd3de5",
     "grade": false,
     "grade_id": "cell-0f2cf5a834bcb81f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 3b-ii)  When $M_r\\geq1$ [5 pts]\n",
    "After you've implemented the jacsim function, run the code below. If implemented correctly, you'll have RMSE below 1.0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2bf9d8963779b9a06356ce350d21d918",
     "grade": false,
     "grade_id": "cell-4477a51f4899a012",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarity calculation time 1.7192324921488762\n",
      "0.991363571262366\n"
     ]
    }
   ],
   "source": [
    "cf = Collaborative(data)\n",
    "Xr = cf.Mr>=1\n",
    "t0=time.perf_counter()\n",
    "cf.calc_item_item_similarity(cf.jacsim,Xr)\n",
    "t1=time.perf_counter()\n",
    "time_sim = t1-t0\n",
    "print('similarity calculation time',time_sim)\n",
    "yp = cf.predict()\n",
    "rmse = cf.rmse(yp)\n",
    "print(rmse)\n",
    "assert(rmse<1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "56d514e593a1e32c7b57a3d18da9495f",
     "grade": true,
     "grade_id": "cell-6103dd685a33c891",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# tests RMSE for jacsim implementation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d6d254c087d53c6f60890bae47c586d8",
     "grade": true,
     "grade_id": "cell-905be3dcffdd989b",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# tests RMSE for jacsim implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f9f6e370bf396f1ba575f3fdc485aedb",
     "grade": true,
     "grade_id": "cell-53a7044088d56bae",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# tests jacsim implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "21d48bfa341828a102aba1dd7124a762",
     "grade": true,
     "grade_id": "cell-113417d673195815",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# tests performance of jacsim implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all cells passed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "140c251a8429e18078d9837647376db1",
     "grade": false,
     "grade_id": "cell-e75eac7e52ab8be3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 3b-iii)  When $M_r$; no transform [5 pts]\n",
    "After you've implemented the jacsim function, run the code below. If implemented correctly, you'll have RMSE below 0.96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "724694f71418cc260320e7a8ab1326f9",
     "grade": false,
     "grade_id": "cell-4089ff635a4df681",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarity calculation time 2.6094931066036224\n",
      "0.9516534264490534\n"
     ]
    }
   ],
   "source": [
    "cf = Collaborative(data)\n",
    "Xr = cf.Mr.astype(int)\n",
    "t0=time.perf_counter()\n",
    "cf.calc_item_item_similarity(cf.jacsim,Xr)\n",
    "t1=time.perf_counter()\n",
    "time_sim = t1-t0\n",
    "print('similarity calculation time',time_sim)\n",
    "yp = cf.predict()\n",
    "rmse = cf.rmse(yp)\n",
    "print(rmse)\n",
    "assert(rmse<0.96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "decd4b7938aa6ca5248052b9de6d5ba9",
     "grade": true,
     "grade_id": "cell-576df690bad55235",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# tests jacsim implementation RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ab5eff4a5d76bd09aa79f9d3cacb640a",
     "grade": true,
     "grade_id": "cell-270a003313f847ff",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# tests jacsim implementation RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "909dc277376a171f715521bde6ee0300",
     "grade": true,
     "grade_id": "cell-a5efeaa7f4bf26a9",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# tests jacsim implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dababdf06535f7785735f1a51c358118",
     "grade": true,
     "grade_id": "cell-15304b41c7ed15d3",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# tests jacsim implementation performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1fefd36b83885e756dd5056f3e3fdf52",
     "grade": false,
     "grade_id": "cell-f384dc5e284c5165",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 3.C Discussion [Peer Review]\n",
    "Answer the questions below in this week's Peer Review assignment. <br>\n",
    "1. Summarize the methods and performances: Below is a template/example.\n",
    "\n",
    "|Method|RMSE|\n",
    "|:----|:--------:|\n",
    "|Baseline, $Y_p$=3| |\n",
    "|Baseline, $Y_p=\\mu_u$| |\n",
    "|Content based, item-item| |\n",
    "|Collaborative, cosine| |\n",
    "|Collaborative, jaccard, $M_r\\geq 3$|  |\n",
    "|Collaborative, jaccard, $M_r\\geq 1$|  |\n",
    "|Collaborative, jaccard, $M_r$|  |\n",
    "\n",
    "2. Discuss which method(s) work better than others and why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2585510334053043\n",
      "1.0352910334228647\n",
      "1.0128116783754684\n",
      "1.0263081874204125\n"
     ]
    }
   ],
   "source": [
    "print(method_yp3)\n",
    "print(method2_ypavg)\n",
    "print(method3_cb_ii)\n",
    "print(method4_cb_cosine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1fefd36b83885e756dd5056f3e3fdf52",
     "grade": false,
     "grade_id": "cell-f384dc5e284c5165",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 3.C Discussion [Peer Review]\n",
    "Answer the questions below in this week's Peer Review assignment. <br>\n",
    "1. Summarize the methods and performances: Below is a template/example.\n",
    "\n",
    "|Method|RMSE|\n",
    "|:----|:--------:|\n",
    "|Baseline, $Y_p$=3| |\n",
    "|Baseline, $Y_p=\\mu_u$| |\n",
    "|Content based, item-item| |\n",
    "|Collaborative, cosine| |\n",
    "|Collaborative, jaccard, $M_r\\geq 3$|  |\n",
    "|Collaborative, jaccard, $M_r\\geq 1$|  |\n",
    "|Collaborative, jaccard, $M_r$|  |\n",
    "\n",
    "2. Discuss which method(s) work better than others and why."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Method|RMSE|\n",
    "|:----|:--------:|\n",
    "|Baseline, $Y_p$=3| 1.2586 |\n",
    "|Baseline, $Y_p=\\mu_u$| 1.0353 |\n",
    "|Content based, item-item| 1.0128 |\n",
    "|Collaborative, cosine| 1.0263 |\n",
    "|Collaborative, jaccard, $M_r\\geq 3$| 0.9819 |\n",
    "|Collaborative, jaccard, $M_r\\geq 1$| 0.9914 |\n",
    "|Collaborative, jaccard, $M_r$| 0.9517 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion:**  \n",
    "\n",
    "Collaborative method using jaccard simmilarity measure demonstrated the best results as mesured by RMSE; in particular, with no transformation on the the original data, i.e. defining similarity matrix based on all levels of ratings.  \n",
    "\n",
    "Improvements in performance were observerd between baseline estimations, content based methods, and collaborative methods.  Methods which capture increasing amounts of information are expected to perform better.  For example, predicting all ratings as 3 doesn't actually capture or utilize any of the underlying information and preferences.  As more information is used, as in setting prediction ratings to the individual user average, performance improves.  \n",
    "\n",
    "Content based and Collaborative based methods are qualitatively different methods from one another.  In comparison, to the baseline methods, both capture more information.  However, the amount of relevant information captured, and in turn the relative improvements in performance will depend on the underlying data and information.  In this example, content based similarity measures were based solely on genre classifications.  However, there are obviously variations within genres or other factors which affect user preferences.  Other detailed information could be used to improve similarity ratings and predictions; for example:  actors, directors, run time (short/long), themes not captured by genre (dystopian, futuristic, mystery, slow-burn, feel good, etc), specific elements (smoking, nudity, violence), and numerous other content based elements.  With greater information about the content, a content based measure could potentially perform better than a collaborative based measure.  Similarly, collaborative based measures will also be affected by the underlying data and information depending on factors such as sparse ratings.  So, depending on the available information and prediction goal, one measure or the other may perform better.\n",
    "\n",
    "Within the collaborative method, increased information capture produced imroved performance.  With the change in threshold value for ratings was adjusted (or not used), differing and more granular information about user past rating is captured resulting in improved performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5f326db8bed1279d8025ccf538456390",
     "grade": false,
     "grade_id": "cell-3c31370d71a476a6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Grading\n",
    "The final score that you will receive for your programming assignment is generated in relation to the total points set in your programming assignment itemâ€”not the total point value in the nbgrader notebook.<br>\n",
    "When calculating the final score shown to learners, the programming assignment takes the percentage of earned points vs. the total points provided by nbgrader and returns a score matching the equivalent percentage of the point value for the programming assignment. <br>\n",
    "**DO NOT CHANGE VARIABLE OR METHOD SIGNATURES** The autograder will not work properly if your change the variable or method signatures. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2b2ef6efc5deee97a474a1b0d8b07bca",
     "grade": false,
     "grade_id": "cell-fb09c135cd86a7c9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Validate Button\n",
    "Please note that this assignment uses nbgrader to facilitate grading. You will see a **validate button** at the top of your Jupyter notebook. If you hit this button, it will run tests cases for the lab that aren't hidden. It is good to use the validate button before submitting the lab. Do know that the labs in the course contain hidden test cases. The validate button will not let you know whether these test cases pass. After submitting your lab, you can see more information about these hidden test cases in the Grader Output. <br>\n",
    "***Cells with longer execution times will cause the validate button to time out and freeze. Please know that if you run into Validate time-outs, it will not affect the final submission grading.*** <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "32e45eb6bcc8c7d1db2d846fc120d426",
     "grade": false,
     "grade_id": "cell-e212d9fd41f03b18",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Building Recommender Systems for Movie Rating Prediction\n",
    "\n",
    "In this assignment, we will build a recommender systems that predict movie ratings. [MovieLense](https://grouplens.org/datasets/movielens/) has currently 25 million user-movie ratings.  Since the entire data is too big, we use  a 1 million ratings subset [MovieLens 1M](https://www.kaggle.com/odedgolden/movielens-1m-dataset), and we reformatted the data to make it more convenient to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "069f66d81507ea520c1fe5098352b437",
     "grade": false,
     "grade_id": "cell-ea989c7a4eb25b70",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.sparse import coo_matrix, csr_matrix\n",
    "from scipy.spatial.distance import jaccard, cosine \n",
    "from pytest import approx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cdeafa5886528c497f33ffde32d9b7bb",
     "grade": false,
     "grade_id": "cell-476e59a408937946",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "MV_users = pd.read_csv('data/users.csv')\n",
    "MV_movies = pd.read_csv('data/movies.csv')\n",
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a0ddf339d993a9dfb1046fa9c762eb28",
     "grade": false,
     "grade_id": "cell-9dea5c452642998d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "Data = namedtuple('Data', ['users','movies','train','test'])\n",
    "data = Data(MV_users, MV_movies, train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "58249f70f1dc6b13ee151e49b58c073b",
     "grade": false,
     "grade_id": "cell-ee6ea083a19e98e4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Starter codes\n",
    "Now, we will be building a recommender system which has various techniques to predict ratings. \n",
    "The `class RecSys` has baseline prediction methods (such as predicting everything to 3 or to average rating of each user) and other utility functions. `class ContentBased` and `class Collaborative` inherit `class RecSys` and further add methods calculating item-item similarity matrix. You will be completing those functions using what we learned about content-based filtering and collaborative filtering.\n",
    "\n",
    "`RecSys`'s `rating_matrix` method converts the (user id, movie id, rating) triplet from the train data (train data's ratings are known) into a utility matrix for 6040 users and 3883 movies.    \n",
    "Here, we create the utility matrix as a dense matrix (numpy.array) format for convenience. But in a real world data where hundreds of millions of users and items may exist, we won't be able to create the utility matrix in a dense matrix format (For those who are curious why, try measuring the dense matrix self.Mr using .nbytes()). In that case, we may use sparse matrix operations as much as possible and distributed file systems and distributed computing will be needed. Fortunately, our data is small enough to fit in a laptop/pc memory. Also, we will use numpy and scipy.sparse, which allow significantly faster calculations than calculating on pandas.DataFrame object.    \n",
    "In the `rating_matrix` method, pay attention to the index mapping as user IDs and movie IDs are not the same as array index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b203240e52b0e6e18286e3797922e639",
     "grade": false,
     "grade_id": "cell-f9c7ee3867550bb6",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class RecSys():\n",
    "    def __init__(self,data):\n",
    "        self.data=data\n",
    "        self.allusers = list(self.data.users['uID'])\n",
    "        self.allmovies = list(self.data.movies['mID'])\n",
    "        self.genres = list(self.data.movies.columns.drop(['mID', 'title', 'year']))\n",
    "        self.mid2idx = dict(zip(self.data.movies.mID,list(range(len(self.data.movies)))))\n",
    "        self.uid2idx = dict(zip(self.data.users.uID,list(range(len(self.data.users)))))\n",
    "        self.Mr=self.rating_matrix()\n",
    "        self.Mm=None \n",
    "        self.sim=np.zeros((len(self.allmovies),len(self.allmovies)))\n",
    "        \n",
    "    def rating_matrix(self):\n",
    "        \"\"\"\n",
    "        Convert the rating matrix to numpy array of shape (#allusers,#allmovies)\n",
    "        \"\"\"\n",
    "        ind_movie = [self.mid2idx[x] for x in self.data.train.mID] \n",
    "        ind_user = [self.uid2idx[x] for x in self.data.train.uID]\n",
    "        rating_train = list(self.data.train.rating)\n",
    "        \n",
    "        return np.array(coo_matrix((rating_train, (ind_user, ind_movie)), shape=(len(self.allusers), len(self.allmovies))).toarray())\n",
    "\n",
    "\n",
    "    def predict_everything_to_3(self):\n",
    "        \"\"\"\n",
    "        Predict everything to 3 for the test data\n",
    "        \"\"\"\n",
    "        # Generate an array with 3s against all entries in test dataset\n",
    "        # your code here\n",
    "        #np.array([3] * len(self.data.test))\n",
    "        #np.ones(shape=(len(self.data.test,))) * 3\n",
    "        return np.ones_like(self.data.test.rating) * 3\n",
    "        \n",
    "        \n",
    "    def predict_to_user_average(self):\n",
    "        \"\"\"\n",
    "        Predict to average rating for the user.\n",
    "        Returns numpy array of shape (#users,)\n",
    "        \"\"\"\n",
    "        # Generate an array as follows:\n",
    "        # 1. Calculate all avg user rating as sum of ratings of user across all movies/number of movies whose rating > 0\n",
    "        # 2. Return the average rating of users in test data\n",
    "        # your code here\n",
    "        mean_ratings = dict()\n",
    "        test_IDs = self.data.test.uID.unique()\n",
    "        for id in test_IDs:\n",
    "            id_idx = self.uid2idx[id]\n",
    "            ratings = self.Mr[id_idx]\n",
    "            mean_ratings[id] = ratings.sum() / np.count_nonzero(ratings)\n",
    "        yp = []\n",
    "        for i in range(len(self.data.test)):\n",
    "            yp.append(mean_ratings[self.data.test.uID[i]])\n",
    "        yp = np.array(yp)\n",
    "        return yp\n",
    "    \n",
    "    def predict_from_sim(self,uid,mid):\n",
    "        \"\"\"\n",
    "        Predict a user rating on a movie given userID and movieID\n",
    "        \"\"\"\n",
    "        # Predict user rating as follows:\n",
    "        # 1. Get entry of user id in rating matrix\n",
    "        # 2. Get entry of movie id in sim matrix\n",
    "        # 3. Employ 1 and 2 to predict user rating of the movie\n",
    "        # your code here\n",
    "        index_userID = self.uid2idx[uid]\n",
    "        ratings_index_userID = self.Mr[index_userID]\n",
    "        index_movieID = self.mid2idx[mid]\n",
    "        movie_sims = self.sim[index_movieID]\n",
    "        sum_of_sims = np.dot(movie_sims, ratings_index_userID !=0)  # sum of sims where rating != 0\n",
    "        rating = np.dot(ratings_index_userID, movie_sims) / sum_of_sims\n",
    "        \n",
    "        # if there are no similar movies, ie all sims=0 then the rating will be 0\n",
    "        # if rating=0 then predict to user average\n",
    "        if rating == 0:\n",
    "            return self.Mr[index_userID].sum() / np.count_nonzero(self.Mr[index_userID])\n",
    "        else:\n",
    "            return rating\n",
    "        # return rating\n",
    "    \n",
    "    def predict(self):\n",
    "        \"\"\"\n",
    "        Predict ratings in the test data. Returns predicted rating in a numpy array of size (# of rows in testdata,)\n",
    "        \"\"\"\n",
    "        # your code here\n",
    "        yp = np.array([])\n",
    "        for i in range(len(self.data.test)):\n",
    "            uID = self.data.test.iloc[i]['uID']\n",
    "            mID = self.data.test.iloc[i]['mID']\n",
    "            rating = self.predict_from_sim(uID, mID)\n",
    "            yp = np.append(yp, rating)\n",
    "        return yp\n",
    "    \n",
    "    def rmse(self,yp):\n",
    "        yp[np.isnan(yp)]=3 #In case there is nan values in prediction, it will impute to 3.\n",
    "        yt=np.array(self.data.test.rating)\n",
    "        return np.sqrt(((yt-yp)**2).mean())\n",
    "\n",
    "    \n",
    "class ContentBased(RecSys):\n",
    "    def __init__(self,data):\n",
    "        super().__init__(data)\n",
    "        self.data=data\n",
    "        self.Mm = self.calc_movie_feature_matrix()  \n",
    "        \n",
    "    def calc_movie_feature_matrix(self):\n",
    "        \"\"\"\n",
    "        Create movie feature matrix in a numpy array of shape (#allmovies, #genres) \n",
    "        \"\"\"\n",
    "        # your code here\n",
    "        m = self.data.movies.drop(['mID', 'title', 'year'], axis=1)\n",
    "        return np.asmatrix(m)\n",
    "    \n",
    "    def calc_item_item_similarity(self):\n",
    "        \"\"\"\n",
    "        Create item-item similarity using Jaccard similarity\n",
    "        \"\"\"\n",
    "        # Update the sim matrix by calculating item-item similarity using Jaccard similarity\n",
    "        # Jaccard Similarity: J(A, B) = |Aâˆ©B| / |AâˆªB| \n",
    "        # your code here\n",
    "        from sklearn.metrics import pairwise_distances\n",
    "        self.sim = (1 - pairwise_distances(self.Mm, metric='jaccard'))\n",
    "        return\n",
    "        \n",
    "                \n",
    "class Collaborative(RecSys):    \n",
    "    def __init__(self,data):\n",
    "        super().__init__(data)\n",
    "        \n",
    "    def calc_item_item_similarity(self, simfunction, *X):     #simfunction:  'cossim', 'jacsim'\n",
    "        \"\"\"\n",
    "        Create item-item similarity using similarity function. \n",
    "        X is an optional transformed matrix of Mr\n",
    "        \"\"\"    \n",
    "        # General function that calculates item-item similarity based on the sim function and data inputed\n",
    "        if len(X)==0:\n",
    "            self.sim = simfunction()            \n",
    "        else:\n",
    "            self.sim = simfunction(X[0]) # *X passes in a tuple format of (X,), to X[0] will be the actual transformed matrix\n",
    "            \n",
    "    def cossim(self):    \n",
    "        \"\"\"\n",
    "        Calculates item-item similarity for all pairs of items using cosine similarity (values from 0 to 1) on utility matrix\n",
    "        Returns a cosine similarity matrix of size (#all movies, #all movies)\n",
    "        \"\"\"\n",
    "        # Return a sim matrix by calculating item-item similarity for all pairs of items using Jaccard similarity\n",
    "        # Cosine Similarity: C(A, B) = (A.B) / (||A||.||B||) \n",
    "        # your code here\n",
    "        \n",
    "        # create X - a transformed/normalized matrix of .Mr (impute user mean rating for 0 and subtract user mean rating from all)\n",
    "        X = self.Mr.copy().astype(float)\n",
    "        for i in range(len(X)):\n",
    "            user_avg = X[i].sum() / np.count_nonzero(X[i])\n",
    "            np.nan_to_num(user_avg, copy=False)\n",
    "            X[i] = np.where(X[i]==0, X[i], X[i] - user_avg)  # ie  where val=0, val stays 0, else where !=0 set val = val - mean\n",
    "\n",
    "        from sklearn.metrics import pairwise_distances\n",
    "        X_sim = (1 - pairwise_distances(X.T, metric='cosine'))\n",
    "        X_sim = 0.5 + (0.5 * X_sim)\n",
    "        return X_sim\n",
    "        # this solution PASSED all cells\n",
    "        \n",
    "#         # Compute **averaged** movie ratings for all users (movie_ratings_allUsers)\n",
    "#         movie_ratings_allUsers = self.Mr.sum(axis=1) / np.count_nonzero(self.Mr, axis=1)\n",
    "#         np.nan_to_num(movie_ratings_allUsers, copy=False)  # default copy=True\n",
    "\n",
    "#         # Create a sparse matrix for operating cosine on its values\n",
    "#         movie_ratings_array = np.repeat(np.expand_dims(movie_ratings_allUsers, axis=1), self.Mr.shape[1], axis=1)\n",
    "\n",
    "#         # Take care of all the zero ratings (missing value/itentionally we don't know)\n",
    "#         movie_ratings_array_adjusted = self.Mr + (self.Mr==0)*movie_ratings_array - movie_ratings_array\n",
    "\n",
    "#         # Average all the ratings: divide by its magnitude!\n",
    "#         MR_avg = movie_ratings_array_adjusted / (np.sqrt((movie_ratings_array_adjusted**2).sum(axis=0)))\n",
    "\n",
    "#         # Put a Boundary check # 1: since dividing by magnitude may produce inf, zeros, etc. Set nans to 0.\n",
    "#         MR_avg = np.nan_to_num(MR_avg)  # or np.nan_to_num(MR_avg, copy=False)\n",
    "\n",
    "#         # Perform an item-item cosine similarity using: np.dot(matrix.T, matrix)\n",
    "#         sim_mat = np.dot(MR_avg.T, MR_avg)\n",
    "\n",
    "#         # Note that the 289 movies with all zero rating will have cosine sim = 0  -  all same-same movie ratings along diagonal should be 1\n",
    "#         #a = np.argwhere(np.diag(sim_mat) == 0)\n",
    "#         #sim_mat[a, a] = 1  \n",
    "#         # still 42 (other vals along diagonal slightly > 1) - use alt method\n",
    "#         idx = range(sim_mat.shape[0])\n",
    "#         sim_mat[idx, idx] = 1\n",
    "\n",
    "#         # Normalized Cosine Formula:\n",
    "#         sim_mat = 0.5 + (0.5 * sim_mat)\n",
    "\n",
    "#         return sim_mat\n",
    "\n",
    "    \n",
    "    def jacsim(self,Xr):\n",
    "        \"\"\"\n",
    "        Calculates item-item similarity for all pairs of items using jaccard similarity (values from 0 to 1)\n",
    "        Xr is the transformed rating matrix.\n",
    "        \"\"\"    \n",
    "        # Return a sim matrix by calculating item-item similarity for all pairs of items using Jaccard similarity\n",
    "        # Jaccard Similarity: J(A, B) = |Aâˆ©B| / |AâˆªB| \n",
    "        # your code here\n",
    "        \n",
    "#         # Convert Xr into a CSR format\n",
    "#         # csr0 = csr_matrix((Xr>0).astype(int))\n",
    "#         X = csr_matrix(Xr)\n",
    "\n",
    "#         # get the intersection\n",
    "#         # produces a n x n matrix of the intersection values, ie [0,1] is the intersection between col 0 and col 1 which is value 3\n",
    "#         a = (X > 0).astype(int)\n",
    "#         nz_intersect = np.dot(a.T, a)\n",
    "        \n",
    "        \n",
    "        n = Xr.shape[1]\n",
    "        max_val = int(Xr.max())\n",
    "        nz_intersect = np.zeros((n,n)).astype(int)\n",
    "        for i in range(1, max_val + 1):\n",
    "                csrm = csr_matrix((Xr == i)).astype(int)\n",
    "                nz_intersect = nz_intersect + np.array(np.dot(csrm.T, csrm).toarray()).astype(int)\n",
    "\n",
    "        # get the union\n",
    "\n",
    "        # get the nonzero counts of each column\n",
    "        #colsums = A.sum(axis=0)  # alternatively\n",
    "        colsums = np.count_nonzero(Xr, axis=0)  # alternatively\n",
    "\n",
    "        # get matrix of sum of colsums between columns\n",
    "        # start with matrix of n x n where row vals = sum for corresponding column eg col 1 = 4, all row[0] vals = 4\n",
    "        n = Xr.shape[1] # how many movies / columns\n",
    "        colsums_mat = np.repeat(colsums.reshape(n,1), n, axis=1)\n",
    "        # add the colsum matrix to its transpose to get the pairs\n",
    "        colsums_pairs = colsums_mat + colsums_mat.T\n",
    "\n",
    "        # to get the union:  subtract the intersection of a pair from the column sums of the two colums  eg col 1 = 4, col 2 = 3; total = 7, int = 3 ---> untion = 4\n",
    "        union = colsums_pairs - nz_intersect\n",
    "\n",
    "        # calculate jaccard similarity\n",
    "        sim = nz_intersect / union\n",
    "        np.nan_to_num(sim, copy=False)  # NaNs potentially generated when union is zero\n",
    "\n",
    "        d = np.argwhere(np.diag(sim) != 1)\n",
    "        sim[d, d] = 1\n",
    "        \n",
    "        return np.array(sim)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7da30c84f0fadd1ae2193af99888f526",
     "grade": false,
     "grade_id": "cell-5efe89bc06f7e6c5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Q1. Baseline models [15 pts]\n",
    "\n",
    "### 1a. Complete the function `predict_everything_to_3` in the class `RecSys`  [5 pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bdd5d6c687c352a1ea45cfed3c7380eb",
     "grade": false,
     "grade_id": "cell-749c77774f53cfe1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Creating Sample test data\n",
    "np.random.seed(42)\n",
    "sample_train = train[:30000]\n",
    "sample_test = test[:30000]\n",
    "\n",
    "\n",
    "sample_MV_users = MV_users[(MV_users.uID.isin(sample_train.uID)) | (MV_users.uID.isin(sample_test.uID))]\n",
    "sample_MV_movies = MV_movies[(MV_movies.mID.isin(sample_train.mID)) | (MV_movies.mID.isin(sample_test.mID))]\n",
    "\n",
    "\n",
    "sample_data = Data(sample_MV_users, sample_MV_movies, sample_train, sample_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6a92dff8931c33032133faadb8a1b370",
     "grade": true,
     "grade_id": "cell-75645797e3541a77",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2642784503423288\n"
     ]
    }
   ],
   "source": [
    "# Sample tests predict_everything_to_3 in class RecSys\n",
    "\n",
    "sample_rs = RecSys(sample_data)\n",
    "sample_yp = sample_rs.predict_everything_to_3()\n",
    "print(sample_rs.rmse(sample_yp))\n",
    "assert sample_rs.rmse(sample_yp)==approx(1.2642784503423288, abs=1e-3), \"Did you predict everything to 3 for the test data?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# passed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "15f5468947b1c6e116c2fa0fd70f70c8",
     "grade": true,
     "grade_id": "cell-52f19a05e8a8b1a3",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2585510334053043\n"
     ]
    }
   ],
   "source": [
    "# Hidden tests predict_everything_to_3 in class RecSys\n",
    "rs = RecSys(data)\n",
    "yp = rs.predict_everything_to_3()\n",
    "print(rs.rmse(yp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2585510334053043\n"
     ]
    }
   ],
   "source": [
    "method_yp3 = rs.rmse(yp)\n",
    "print(method_yp3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# passed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "38a23786301e38ef9c85f0c3620a0a9b",
     "grade": false,
     "grade_id": "cell-e32e46bf9f33dbb3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1b. Complete the function predict_to_user_average in the class RecSys [10 pts]\n",
    "Hint: Include rated items only when averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     def predict_to_user_average(self):\n",
    "#         all_ratings = pd.concat((self.data.train, self.data.test))\n",
    "#         uIDs = all_ratings.uID.unique()\n",
    "#         avg_user_ratings = dict()\n",
    "#         for uID in uIDs:\n",
    "#             avg_rating = self.data.train[(self.data.train.uID == uID) & (self.data.train.rating > 0)].rating.mean()\n",
    "#             avg_user_ratings[uID] = avg_rating\n",
    "#         yp = np.array([])\n",
    "#         for index, row in self.data.test.iterrows():\n",
    "#             yp = np.append(yp, avg_user_ratings[row['uID']])\n",
    "#         return yp\n",
    "\n",
    "# passes both tests below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_ratings = dict()\n",
    "# test_IDs = sample_rs.data.test.uID.unique()\n",
    "# for id in test_IDs:\n",
    "#     id_idx = sample_rs.uid2idx[id]\n",
    "#     ratings = sample_rs.Mr[id_idx]\n",
    "#     mean_ratings[id] = ratings.sum() / np.count_nonzero(ratings)\n",
    "    \n",
    "# yp = np.array([])\n",
    "# for index, row in sample_rs.data.test.iterrows():\n",
    "#     yp = np.append(yp, mean_ratings[row['uID']])\n",
    "\n",
    "# yp = []\n",
    "# for i in range(len(sample_rs.data.test)):\n",
    "#     yp.append(mean_ratings[sample_rs.data.test.uID[i]])\n",
    "# yp = np.array(yp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7939100c207d632a6588064be95e86d1",
     "grade": true,
     "grade_id": "cell-5f918ef5c3068eb7",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1429596846619763\n"
     ]
    }
   ],
   "source": [
    "# Sample tests predict_to_user_average in the class RecSys\n",
    "sample_yp = sample_rs.predict_to_user_average()\n",
    "print(sample_rs.rmse(sample_yp))\n",
    "assert sample_rs.rmse(sample_yp)==approx(1.1429596846619763, abs=1e-3), \"Check predict_to_user_average in the RecSys class. Did you predict to average rating for the user?\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# passed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "870acf1d0ebd4b98fe4d170503948eb7",
     "grade": true,
     "grade_id": "cell-dbe3ae17d138f001",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0352910334228647\n"
     ]
    }
   ],
   "source": [
    "# Hidden tests predict_to_user_average in the class RecSys\n",
    "yp = rs.predict_to_user_average()\n",
    "print(rs.rmse(yp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0352910334228647\n"
     ]
    }
   ],
   "source": [
    "method2_ypavg = rs.rmse(yp)\n",
    "print(method2_ypavg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# passed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "531bc11d4bb9ad16238bb3c6436cf1de",
     "grade": false,
     "grade_id": "cell-2e517f5f3bb7bc8e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Q2. Content-Based model [25 pts]\n",
    "\n",
    "### 2a. Complete the function calc_movie_feature_matrix in the class ContentBased [5 pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9f4e132a376edada87d141fbcbabcdf9",
     "grade": false,
     "grade_id": "cell-0fd9bcbcf2e542fd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "cb = ContentBased(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "16dc8acd6f1516386ebd64246d791bcc",
     "grade": true,
     "grade_id": "cell-232d6022e1da2f62",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# tests calc_movie_feature_matrix in the class ContentBased \n",
    "assert(cb.Mm.shape==(3883, 18))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# passed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e149458337a6465af9cdafbef0cb872d",
     "grade": false,
     "grade_id": "cell-a959245b68dc1033",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 2b. Complete the function calc_item_item_similarity in the class ContentBased [10 pts]\n",
    "This function updates `self.sim` and does not return a value.    \n",
    "Some factors to think about:     \n",
    "1. The movie feature matrix has binary elements. Which similarity metric should be used?\n",
    "2. What is the computation complexity (time complexity) on similarity calcuation?      \n",
    "Hint: You may use functions in the `scipy.spatial.distance` module on the dense matrix, but it is quite slow (think about the time complexity). If you want to speed up, you may try using functions in the `scipy.sparse` module. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3152.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import pairwise_distances\n",
    "my_cb = ContentBased(sample_data)\n",
    "sim_mat = (1 - pairwise_distances(my_cb.Mm, metric='jaccard'))\n",
    "np.trace(sim_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3152.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.spatial.distance import pdist, squareform\n",
    "sim_mat = (1 - squareform(pdist(my_cb.Mm, metric='jaccard')))\n",
    "np.trace(sim_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb.calc_item_item_similarity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7bfb32e08a1d2ecab886c4926f35af4b",
     "grade": true,
     "grade_id": "cell-b88ed74a662c75ac",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Sample tests calc_item_item_similarity in ContentBased class \n",
    "\n",
    "sample_cb = ContentBased(sample_data)\n",
    "sample_cb.calc_item_item_similarity() \n",
    "\n",
    "# print(np.trace(sample_cb.sim))\n",
    "# print(sample_cb.sim[10:13,10:13])\n",
    "assert(sample_cb.sim.sum() > 0), \"Check calc_item_item_similarity.\"\n",
    "assert(np.trace(sample_cb.sim) == 3152), \"Check calc_item_item_similarity. What do you think np.trace(cb.sim) should be?\"\n",
    "\n",
    "\n",
    "ans = np.array([[1, 0.25, 0.],[0.25, 1, 0.],[0., 0., 1]])\n",
    "for pred, true in zip(sample_cb.sim[10:13, 10:13], ans):\n",
    "    assert approx(pred, 0.01) == true, \"Check calc_item_item_similarity. Look at cb.sim\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "86d346bdb7d00d615f915bc87c7c0e8b",
     "grade": true,
     "grade_id": "cell-b1260c5ba472d43b",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# tests calc_item_item_similarity in ContentBased class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7b236c6f66a5cd271b27120fadb39cfa",
     "grade": true,
     "grade_id": "cell-4a8dc462fa8d33f0",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# additional tests for calc_item_item_similarity in ContentBased class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cffd601726e01f148136dccbd545d8fc",
     "grade": true,
     "grade_id": "cell-3b1eb8e79527f012",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# additional tests for calc_item_item_similarity in ContentBased class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "475617bb2e9c2f8ef44e29fd789e3bed",
     "grade": true,
     "grade_id": "cell-64689afe942eba5a",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# additional tests for calc_item_item_similarity in ContentBased class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d36bff79d05688a58351743d920c579e",
     "grade": true,
     "grade_id": "cell-a7be29cab0d2e38a",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# additional tests for calc_item_item_similarity in ContentBased class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# passed all above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6e97e513ad0659d93e513354f7d6a1bd",
     "grade": false,
     "grade_id": "cell-eec0c5d6e29e72f5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 2c. Complete the function predict_from_sim in the class RecSys [5 pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2c791b828031bb24a9c0df5af8102a25",
     "grade": true,
     "grade_id": "cell-2d79f53ecabb1abf",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# for a, b in zip(sample_MV_users.uID, sample_MV_movies.mID):\n",
    "#     print(a, b, sample_cb.predict_from_sim(a,b))\n",
    "\n",
    "# Sample tests for predict_from_sim in RecSys class \n",
    "assert(sample_cb.predict_from_sim(245,276)==approx(2.5128205128205128,abs=1e-2)), \"Check predict_from_sim. Look at how you predicted a user rating on a movie given UserID and movieID.\"\n",
    "assert(sample_cb.predict_from_sim(2026,2436)==approx(2.785714285714286,abs=1e-2)), \"Check predict_from_sim. Look at how you predicted a user rating on a movie given UserID and movieID.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# passed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index_userID = sample_cb.uid2idx[245]\n",
    "# ratings_index_userID = sample_cb.Mr[index_userID]\n",
    "# index_movieID = sample_cb.mid2idx[276]\n",
    "# movie_sims = sample_cb.sim[index_movieID]\n",
    "\n",
    "# sum_of_sims = np.dot(movie_sims, ratings_index_userID !=0)\n",
    "# np.dot(ratings_index_userID, movie_sims) / sum_of_sims\n",
    "\n",
    "# # idx = np.nonzero(np.array(ratings_index_userID))\n",
    "# # x = np.array(movie_sims)[idx].sum()\n",
    "# # np.dot(ratings_index_userID, movie_sims) / x\n",
    "\n",
    "# # if the rating is zero, ie all similarity scores ar zero, then compute user average\n",
    "# sample_cb.Mr[index_userID].sum() / np.count_nonzero(sample_cb.Mr[index_userID])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "55a16fffbf7cbf657fc0133973bddc59",
     "grade": true,
     "grade_id": "cell-a83193bd93c45044",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# tests for predict_from_sim in RecSys class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# passed - only after multiple attempts and finally kernel restart!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1dfb42c210f38f2b616193822663af52",
     "grade": false,
     "grade_id": "cell-4dbdef2549c27d3b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 2d. Complete the function predict in the class RecSys [5 pts]\n",
    "After completing the predict method in the RecSys class, run the cell below to calculate rating prediction and RMSE. How much does the performance increase compared to the baseline results from above? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e8c34be7bd867ea3521024fb6ab4a03c",
     "grade": true,
     "grade_id": "cell-7d6e299ec837ac9e",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1962537249116723\n"
     ]
    }
   ],
   "source": [
    "# Sample tests method predict in the RecSys class \n",
    "\n",
    "sample_yp = sample_cb.predict()\n",
    "sample_rmse = sample_cb.rmse(sample_yp)\n",
    "print(sample_rmse)\n",
    "\n",
    "assert(sample_rmse==approx(1.1962537249116723, abs=1e-2)), \"Check method predict in the RecSys class.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# passed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yp = np.array([])\n",
    "# for i in range(len(sample_cb.data.test)):\n",
    "#     uID = sample_cb.data.test.iloc[i]['uID']\n",
    "#     mID = sample_cb.data.test.iloc[i]['mID']\n",
    "#     rating = sample_cb.predict_from_sim(uID, mID)\n",
    "#     yp = np.append(yp, rating)\n",
    "\n",
    "# sample_cb.rmse(yp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "00c2f93e788dd22360e67f5ef88521a7",
     "grade": false,
     "grade_id": "cell-3232e0e311e56e19",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0128116783754684\n"
     ]
    }
   ],
   "source": [
    "# Hidden tests method predict in the RecSys class \n",
    "\n",
    "yp = cb.predict()\n",
    "rmse = cb.rmse(yp)\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fec9587776c5364a637967f5ec7067cf",
     "grade": true,
     "grade_id": "cell-a8a3fa60da47abcf",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# tests method predict in the RecSys class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0128116783754684\n"
     ]
    }
   ],
   "source": [
    "method3_cb_ii = rmse\n",
    "print(method3_cb_ii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# passed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "44f2a6ef3ef78c7ffa924dd74e309beb",
     "grade": false,
     "grade_id": "cell-563e07a0cadec0db",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Q3. Collaborative Filtering\n",
    "\n",
    "### 3a. Complete the function cossim in the class Collaborative [10 pts]\n",
    "**To Do:**    \n",
    "1.Impute the unrated entries in self.Mr to the user's average rating then subtract by the user mean, call this matrix X.   \n",
    "2.Calculate cosine similarity for all item-item pairs. Don't forget to rescale the cosine similarity to be 0~1.    \n",
    "You might encounter divide by zero warning (numpy will fill nan value for that entry). In that case, you can fill those with appropriate values.    \n",
    "\n",
    "Hint: Let's say a movie item has not been rated by anyone. When you calculate similarity of this vector to anoter, you will get $\\vec{0}$=[0,0,0,....,0]. When you normalize this vector, you'll get divide by zero warning and it will make nan value in self.sim matrix. Theoretically what should the similarity value for $\\vec{x}_i \\cdot \\vec{x}_i$ when $\\vec{x}_i = \\vec{0}$? What about $\\vec{x}_i \\cdot \\vec{x}_j$ when $\\vec{x}_i = \\vec{0}$ and $\\vec{x}_j$ is an any vector?     \n",
    "\n",
    "Hint: You may use `scipy.spatial.distance.cosine`, but it will be slow because its cosine function does vector-vector operation whereas you can implement matrix-matrix operation using numpy to calculate all cosines all at once (it can be 100 times faster than vector-vector operation in our data). Also pay attention to the definition. The scipy.spatial.distance provides distance, not similarity. \n",
    "\n",
    "3. Run the below cell that calculate yp and RMSE. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4b6366ed3397587780416b7fa65f1456",
     "grade": true,
     "grade_id": "cell-054a0416525e124f",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Sample tests cossim method in the Collaborative class\n",
    "\n",
    "sample_cf = Collaborative(sample_data)\n",
    "sample_cf.calc_item_item_similarity(sample_cf.cossim)\n",
    "sample_yp = sample_cf.predict()\n",
    "sample_rmse = sample_cf.rmse(sample_yp)\n",
    "\n",
    "assert(np.trace(sample_cf.sim)==3152), \"Check cossim method in the Collaborative class. What should np.trace(cf.sim) equal?\"\n",
    "assert(sample_rmse==approx(1.1429596846619763, abs=5e-3)), \"Check cossim method in the Collaborative class. rmse result is not as expected.\"\n",
    "assert(sample_cf.sim[0,:3]==approx([1., 0.5, 0.5],abs=1e-2)), \"Check cossim method in the Collaborative class. cf.sim isn't giving the expected results.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# passed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = sample_cf.Mr.copy()\n",
    "# for i in range(len(X)):\n",
    "#     user_avg = X[i].sum() / np.count_nonzero(X[i])\n",
    "#     X[i] = np.where(X[i]==0, X[i], X[i] - user_avg)  # ie  where val=0, val stays 0, else where !=0 set val = val - mean\n",
    "\n",
    "# from sklearn.metrics import pairwise_distances\n",
    "# X_sim = (1 - pairwise_distances(X.T, metric='cosine'))\n",
    "# X_sim = 0.5 + (0.5 * X_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18153888\n",
      "30000\n",
      "False\n",
      "total rows: 5769\n",
      "rows all zero: 585\n",
      "rows not all zero: 5184\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([   0,    0,    1, ..., 5768, 5768, 5768]),\n",
       " array([ 463,  518,  694, ..., 1121, 1793, 2819]))"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.count_nonzero(sample_cf.Mr==0))  # how many values are zero?\n",
    "print(np.count_nonzero(sample_cf.Mr))     # how many values are non zero?\n",
    "print(np.any(np.isnan(sample_cf.Mr)))     # are any values NaN?\n",
    "print('total rows:', sample_cf.Mr.shape[0])\n",
    "print('rows all zero:', np.all(sample_cf.Mr==0, axis=1).sum())  # how many rows are all zero?\n",
    "print('rows not all zero:', np.any(sample_cf.Mr, axis=1).sum())     # how many rows have at least one rating?\n",
    "\n",
    "np.nonzero(sample_cf.Mr)  # returns tuple of indices of nonzero values (array of dim_1, array of dim_2)\n",
    "np.where(sample_cf.Mr!=0) # equivalent to np.nonzero - returns indices where val!=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.9403746653744962"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cosine calculation examples from lecture\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "a = np.array([5, 0, 1, 4])\n",
    "b = np.array([2, 3, 5, 0])\n",
    "c = np.array([4, 4, 0, 4])\n",
    "(1 - cosine(a, b))  # 0.375\n",
    "\n",
    "# impute Nan/0 to neutral value 3\n",
    "a = np.array([5, 3, 1, 4])\n",
    "b = np.array([2, 3, 5, 3])\n",
    "c = np.array([4, 4, 3, 4])\n",
    "(1 - cosine(a, b))  # 0.74\n",
    "\n",
    "# impute to 3 (and subtract 3)\n",
    "a = np.array([5, 3, 1, 4]) - 3\n",
    "b = np.array([2, 3, 5, 3]) - 3\n",
    "(1 - cosine(a, b))  # -0.89\n",
    "\n",
    "# normalize by user mean:  impute NaN/0 vals to mean (and subtract mean from all)\n",
    "a = np.array([5, 3.25, 1, 4, 3]) - 3.25\n",
    "b = np.array([2, 3, 5, 3.25, 3]) - 3.25\n",
    "(1 - cosine(a, b))  # -0.94"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example of np.expand\n",
    "# np.expand_dims(a, axis)\n",
    "x = np.array([1, 2])\n",
    "x.shape # (2,)\n",
    "y = np.expand_dims(x, axis=0)  # equivalent to x[np.newaxis, :] or x[np.newaxis]\n",
    "y.shape # (1, 2)\n",
    "y = np.expand_dims(x, axis=1)  # equivalent to x[:, np.newaxis]\n",
    "y.shape # (2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 2, 2, 2],\n",
       "       [3, 3, 3, 4, 4, 4]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example of np.repeat\n",
    "# np.repeat(a, repeats, axis=None)   Output array which has the same shape as a, except along the given axis\n",
    "np.repeat(3, 4)\n",
    "x = np.array([[1,2],[3,4]])\n",
    "np.repeat(x, 2)\n",
    "np.repeat(x, 3, axis=1)    #np.repeat(x, 3, axis=0)\n",
    "# np.repeat(x, [1, 2], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = sample_cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute **averaged** movie ratings for all users (movie_ratings_allUsers)\n",
    "movie_ratings_allUsers = test.Mr.sum(axis=1) / np.count_nonzero(test.Mr, axis=1)\n",
    "np.isnan(movie_ratings_allUsers).sum() #585 NaNs\n",
    "\n",
    "# replace the NaNs with 0\n",
    "np.nan_to_num(movie_ratings_allUsers, copy=False)  # default copy=True\n",
    "np.isnan(movie_ratings_allUsers).sum()  # 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5769, 3152)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a sparse matrix for operating cosine on its values\n",
    "movie_ratings_array = np.repeat(np.expand_dims(movie_ratings_allUsers, axis=1), test.Mr.shape[1], axis=1)\n",
    "movie_ratings_array.shape # (5769, 3152)  # no NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5769, 3152)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take care of all the zero ratings (missing value/itentionally we don't know)\n",
    "movie_ratings_array_adjusted = test.Mr + (test.Mr==0)*movie_ratings_array - movie_ratings_array\n",
    "# takes the original Mr, uses a bool matrix (where vals==0) * ratings to impute all zero vals to the mean for user\n",
    "# then subtracts the mean from all values\n",
    "movie_ratings_array_adjusted.shape  # (5769, 3152)  # no NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "289"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# are there columns that are all zero?  that will produce a norm=zero and div/0 --> NaN\n",
    "np.all(movie_ratings_array_adjusted == 0, axis=0).sum() #289"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average all the ratings: divide by its magnitude!\n",
    "MR_avg = movie_ratings_array_adjusted / (np.sqrt((movie_ratings_array_adjusted**2).sum(axis=0)))\n",
    "# note that np.sqrt((movie_ratings_array_adjusted**2).sum(axis=0)) should be equivalent to \n",
    "#    np.linalg.norm(movie_ratings_array_adjusted, ord=2, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "289"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(MR_avg).sum()  # 5769 users x 289 movies with all zero ratings = 1667241\n",
    "np.all(np.isnan(MR_avg), axis=0).sum()  # 289 columns with all NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "289"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Put a Boundary check # 1: since dividing by magnitude may produce inf, zeros, etc. Set nans to 0.\n",
    "\n",
    "# numpy.nan_to_num(x, copy=True, nan=0.0, posinf=None, neginf=None)\n",
    "MR_avg = np.nan_to_num(MR_avg)  # or np.nan_to_num(MR_avg, copy=False)\n",
    "MR_avg.shape  # (5769, 3152)\n",
    "np.isnan(MR_avg).sum() # 0\n",
    "np.count_nonzero(np.all(MR_avg == 0, axis=0))  # 289 columns are all zero (as expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform an item-item cosine similarity using: np.dot(matrix.T, matrix)\n",
    "sim_mat = np.dot(MR_avg.T, MR_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2863.0"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note that the 289 movies with all zero rating will have cosine sim = 0\n",
    "sim_mat.shape     # (3152, 3152)\n",
    "sim_mat.trace()   # trace is 2863 (not 3152)\n",
    "np.count_nonzero(np.diag(sim_mat) == 0)  # 289"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3152.0"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.argwhere(np.diag(sim_mat) == 0)\n",
    "b = np.argwhere(np.all(movie_ratings_array_adjusted == 0, axis=0))\n",
    "np.all(np.equal(a, b))  # True\n",
    "\n",
    "sim_mat[a, b].sum()\n",
    "sim_mat[a, a].sum()  # 0\n",
    "\n",
    "sim_mat[a, a] = 1\n",
    "sim_mat.trace()  # 3152"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# But note!\n",
    "np.count_nonzero(np.diag(sim_mat) > 1) # 42\n",
    "# must be corrected to 1 - autograder checks max == 1\n",
    "sim_mat[range(sim_mat.shape[0]), range(sim_mat.shape[0])] = 1\n",
    "np.count_nonzero(np.diag(sim_mat) > 1)  # 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3152.0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalized Cosine Formula:\n",
    "sim_mat = 0.5 + (0.5 * sim_mat)\n",
    "sim_mat.trace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5eb656568ac143aa7e40c212d53eb020",
     "grade": false,
     "grade_id": "cell-49a2c83fd032cee6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0263081874204125\n"
     ]
    }
   ],
   "source": [
    "# Hidden tests cossim method in the Collaborative class\n",
    "\n",
    "cf = Collaborative(data)\n",
    "cf.calc_item_item_similarity(cf.cossim)\n",
    "yp = cf.predict()\n",
    "rmse = cf.rmse(yp)\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method \"B\" rmse = 1.0263081874204125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0263081874204125\n"
     ]
    }
   ],
   "source": [
    "method4_cb_cosine = rmse\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "31b5a8be7a888dea0fba0148175c7622",
     "grade": true,
     "grade_id": "cell-126fb0d12b2c66e7",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# tests cossim method in the Collaborative class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "800ff371c38a877b0285b0f45cc18f1a",
     "grade": true,
     "grade_id": "cell-9e6bc1c31e566d76",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# additional tests for cossim method in the Collaborative class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d85d53d1945355c60edbd3eb99a2223a",
     "grade": true,
     "grade_id": "cell-7b9c0acd25eaadda",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# additional tests for cossim method in the Collaborative class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a7bd4b4a85ca2d4efa551f602bde298f",
     "grade": true,
     "grade_id": "cell-369189aa9a403a0f",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# additional tests for cossim method in the Collaborative class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b337a1c35dade446f7572c74d2a14fe6",
     "grade": true,
     "grade_id": "cell-bfde47a18fccd03d",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# additional tests for cossim method in the Collaborative class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3ff727b57a52eb37221feb12d09e0f7a",
     "grade": true,
     "grade_id": "cell-cb7766e929ce12ef",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# additional tests for cossim method in the Collaborative class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all cells passed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "15dbe8e3743dd847b4292cc46184e163",
     "grade": false,
     "grade_id": "cell-6dd829484cdb0a9f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 3b. Complete the function jacsim in the class Collaborative [15 pts]\n",
    "**3b [15 pts] = 3b-i) [5 pts]+3b-ii) [5 pts]+ 3b-iii) [5 pts]**\n",
    "\n",
    "Function `jacsim` calculates jaccard similarity between items using collaborative filtering method. When we have a rating matrix `self.Mr`, the entries of Mr matrix are 0 to 5 (0: unrated, 1-5: rating). We are interested to see which threshold method works better when we use jaccard dimilarity in the collaborative filtering.    \n",
    "We may treat any rating 3 or above to be 1 and the negatively rated (below 3) and no-rating as 0. Or, we may treat movies with any ratings to be 1 and ones that has no rating as 0. In this question, we will complete a function jacsim that takes a transformed rating matrix X and calculate and returns a jaccard similarity matrix.     \n",
    "Let's consider these input cases for the utility matrix $M_r$ with ratings 1-5 and 0s for no-rating.    \n",
    "1. $M_r \\geq 3$ \n",
    "2. $M_r \\geq 0$ \n",
    "3. $M_r$, no transform.\n",
    "\n",
    "Things to think about: \n",
    "- The cases 1 and 2 are straightforward to calculate Jaccard, but what does Jaccard mean for multicategory data?\n",
    "- Time complexity: The matrix $M_r$ is much bigger than the item feature matrix $M_m$, therefore it will take very long time if we calculate on dense matrix.     \n",
    "Hint: Use sparse matrix.\n",
    "- Which method will give the best performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4e73ce8798c3e0387a575fb5b47b628c",
     "grade": false,
     "grade_id": "cell-3cc4678686ede231",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 3b-i)  When $M_r\\geq3$ [5 pts]\n",
    "After you've implemented the jacsim function, run the code below. If implemented correctly, you'll have RMSE below 0.99. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d80694c2f4ea5b45f954a89f29d4e9a1",
     "grade": false,
     "grade_id": "cell-e0d9354a7b488cca",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarity calculation time 1.5387999191880226\n",
      "0.9819058692126349\n"
     ]
    }
   ],
   "source": [
    "cf = Collaborative(data)\n",
    "Xr = cf.Mr>=3\n",
    "t0=time.perf_counter()\n",
    "cf.calc_item_item_similarity(cf.jacsim,Xr)\n",
    "t1=time.perf_counter()\n",
    "time_sim = t1-t0\n",
    "print('similarity calculation time',time_sim)\n",
    "yp = cf.predict()\n",
    "rmse = cf.rmse(yp)\n",
    "print(rmse)\n",
    "assert(rmse<0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "71319b1d93a7f9232023bf05ea90202e",
     "grade": true,
     "grade_id": "cell-a80d917298a5c254",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# tests RMSE for jacsim implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4997d897c391218cac8f5c3aaf2bcc07",
     "grade": true,
     "grade_id": "cell-fdebe2b922817f71",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# additional tests for RMSE for jacsim implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3f81809af169f5c527bca4a1738f646f",
     "grade": true,
     "grade_id": "cell-ba2fba2da48d3160",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# additional tests for jacsim implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** did not pass single cell above ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "49c97e825ef7bd0b32ab4ad5bc378458",
     "grade": true,
     "grade_id": "cell-f7e1c6f239e3155f",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# additional tests for jacsim implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# passed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d7d6ac2ac83c2e4a79834f05debd3de5",
     "grade": false,
     "grade_id": "cell-0f2cf5a834bcb81f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 3b-ii)  When $M_r\\geq1$ [5 pts]\n",
    "After you've implemented the jacsim function, run the code below. If implemented correctly, you'll have RMSE below 1.0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2bf9d8963779b9a06356ce350d21d918",
     "grade": false,
     "grade_id": "cell-4477a51f4899a012",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarity calculation time 1.7192324921488762\n",
      "0.991363571262366\n"
     ]
    }
   ],
   "source": [
    "cf = Collaborative(data)\n",
    "Xr = cf.Mr>=1\n",
    "t0=time.perf_counter()\n",
    "cf.calc_item_item_similarity(cf.jacsim,Xr)\n",
    "t1=time.perf_counter()\n",
    "time_sim = t1-t0\n",
    "print('similarity calculation time',time_sim)\n",
    "yp = cf.predict()\n",
    "rmse = cf.rmse(yp)\n",
    "print(rmse)\n",
    "assert(rmse<1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "56d514e593a1e32c7b57a3d18da9495f",
     "grade": true,
     "grade_id": "cell-6103dd685a33c891",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# tests RMSE for jacsim implementation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d6d254c087d53c6f60890bae47c586d8",
     "grade": true,
     "grade_id": "cell-905be3dcffdd989b",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# tests RMSE for jacsim implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f9f6e370bf396f1ba575f3fdc485aedb",
     "grade": true,
     "grade_id": "cell-53a7044088d56bae",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# tests jacsim implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "21d48bfa341828a102aba1dd7124a762",
     "grade": true,
     "grade_id": "cell-113417d673195815",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# tests performance of jacsim implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all cells passed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "140c251a8429e18078d9837647376db1",
     "grade": false,
     "grade_id": "cell-e75eac7e52ab8be3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 3b-iii)  When $M_r$; no transform [5 pts]\n",
    "After you've implemented the jacsim function, run the code below. If implemented correctly, you'll have RMSE below 0.96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "724694f71418cc260320e7a8ab1326f9",
     "grade": false,
     "grade_id": "cell-4089ff635a4df681",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarity calculation time 2.6094931066036224\n",
      "0.9516534264490534\n"
     ]
    }
   ],
   "source": [
    "cf = Collaborative(data)\n",
    "Xr = cf.Mr.astype(int)\n",
    "t0=time.perf_counter()\n",
    "cf.calc_item_item_similarity(cf.jacsim,Xr)\n",
    "t1=time.perf_counter()\n",
    "time_sim = t1-t0\n",
    "print('similarity calculation time',time_sim)\n",
    "yp = cf.predict()\n",
    "rmse = cf.rmse(yp)\n",
    "print(rmse)\n",
    "assert(rmse<0.96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "decd4b7938aa6ca5248052b9de6d5ba9",
     "grade": true,
     "grade_id": "cell-576df690bad55235",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# tests jacsim implementation RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ab5eff4a5d76bd09aa79f9d3cacb640a",
     "grade": true,
     "grade_id": "cell-270a003313f847ff",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# tests jacsim implementation RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "909dc277376a171f715521bde6ee0300",
     "grade": true,
     "grade_id": "cell-a5efeaa7f4bf26a9",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# tests jacsim implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dababdf06535f7785735f1a51c358118",
     "grade": true,
     "grade_id": "cell-15304b41c7ed15d3",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# tests jacsim implementation performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1fefd36b83885e756dd5056f3e3fdf52",
     "grade": false,
     "grade_id": "cell-f384dc5e284c5165",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 3.C Discussion [Peer Review]\n",
    "Answer the questions below in this week's Peer Review assignment. <br>\n",
    "1. Summarize the methods and performances: Below is a template/example.\n",
    "\n",
    "|Method|RMSE|\n",
    "|:----|:--------:|\n",
    "|Baseline, $Y_p$=3| |\n",
    "|Baseline, $Y_p=\\mu_u$| |\n",
    "|Content based, item-item| |\n",
    "|Collaborative, cosine| |\n",
    "|Collaborative, jaccard, $M_r\\geq 3$|  |\n",
    "|Collaborative, jaccard, $M_r\\geq 1$|  |\n",
    "|Collaborative, jaccard, $M_r$|  |\n",
    "\n",
    "2. Discuss which method(s) work better than others and why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2585510334053043\n",
      "1.0352910334228647\n",
      "1.0128116783754684\n",
      "1.0263081874204125\n"
     ]
    }
   ],
   "source": [
    "print(method_yp3)\n",
    "print(method2_ypavg)\n",
    "print(method3_cb_ii)\n",
    "print(method4_cb_cosine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1fefd36b83885e756dd5056f3e3fdf52",
     "grade": false,
     "grade_id": "cell-f384dc5e284c5165",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 3.C Discussion [Peer Review]\n",
    "Answer the questions below in this week's Peer Review assignment. <br>\n",
    "1. Summarize the methods and performances: Below is a template/example.\n",
    "\n",
    "|Method|RMSE|\n",
    "|:----|:--------:|\n",
    "|Baseline, $Y_p$=3| |\n",
    "|Baseline, $Y_p=\\mu_u$| |\n",
    "|Content based, item-item| |\n",
    "|Collaborative, cosine| |\n",
    "|Collaborative, jaccard, $M_r\\geq 3$|  |\n",
    "|Collaborative, jaccard, $M_r\\geq 1$|  |\n",
    "|Collaborative, jaccard, $M_r$|  |\n",
    "\n",
    "2. Discuss which method(s) work better than others and why."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Method|RMSE|\n",
    "|:----|:--------:|\n",
    "|Baseline, $Y_p$=3| 1.2586 |\n",
    "|Baseline, $Y_p=\\mu_u$| 1.0353 |\n",
    "|Content based, item-item| 1.0128 |\n",
    "|Collaborative, cosine| 1.0263 |\n",
    "|Collaborative, jaccard, $M_r\\geq 3$| 0.9819 |\n",
    "|Collaborative, jaccard, $M_r\\geq 1$| 0.9914 |\n",
    "|Collaborative, jaccard, $M_r$| 0.9517 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion:**  \n",
    "\n",
    "The collaborative method using Jaccard similarity measure demonstrated the best results as measured by RMSE; in particular, with no transformation on the original data i.e., defining similarity matrix based on all levels of ratings.  \n",
    "\n",
    "Improvements in performance were observed between baseline estimations, content based methods, and collaborative methods.  Methods which capture increasing amounts of information are expected to perform better.  For example, predicting all ratings as 3 doesn't actually capture or utilize any of the underlying information and preferences.  As more information is used, as in setting prediction ratings to the individual user average, performance improves.  \n",
    "\n",
    "Content based and Collaborative based methods are qualitatively different methods from one another.  In comparison, to the baseline methods, both capture more information.  However, the amount of relevant information captured, and in turn the relative improvements in performance will depend on the underlying data and information.  In this example, content based similarity measures were based solely on genre classifications.  However, there are obviously variations within genres or other factors which affect user preferences.  Other detailed information could be used to improve similarity ratings and predictions; for example:  actors, directors, run time (short/long), themes not captured by genre (dystopian, futuristic, mystery, slow burn, feel good, etc.), specific elements (smoking, nudity, violence), and numerous other content based elements.  With greater information about the content, a content based measure could potentially perform better than a collaborative based measure.  Similarly, collaborative based measures will also be affected by the underlying data and information depending on factors such as sparse ratings.  So, depending on the available information and prediction goal, one measure or the other may perform better.\n",
    "\n",
    "Within the collaborative method, increased information capture produced improved performance.  With the change in threshold value for ratings was adjusted (or not used), differing and more granular information about user past rating is captured resulting in improved performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
